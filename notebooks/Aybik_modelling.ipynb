{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>minute</th>\n",
       "      <th>rating</th>\n",
       "      <th>key</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>actor_list</th>\n",
       "      <th>language</th>\n",
       "      <th>studio_list</th>\n",
       "      <th>crew_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Barbie and Ken are having the time of their li...</td>\n",
       "      <td>114</td>\n",
       "      <td>3.86</td>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>comedy adventure</td>\n",
       "      <td>['Margot Robbie', 'Ryan Gosling', 'America Fer...</td>\n",
       "      <td>English</td>\n",
       "      <td>['LuckyChap Entertainment', 'Heyday Films', 'N...</td>\n",
       "      <td>{'Cinematography': ['Rodrigo Prieto'], 'Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>All unemployed, Ki-taek's family takes peculia...</td>\n",
       "      <td>133</td>\n",
       "      <td>4.56</td>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>comedy thriller drama</td>\n",
       "      <td>['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...</td>\n",
       "      <td>Korean</td>\n",
       "      <td>['Barunson E&amp;A']</td>\n",
       "      <td>{'Cinematography': ['Hong Kyung-pyo'], 'Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>An aging Chinese immigrant is swept up in an i...</td>\n",
       "      <td>140</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>science_fiction adventure comedy action</td>\n",
       "      <td>['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...</td>\n",
       "      <td>English</td>\n",
       "      <td>['IAC Films', 'AGBO', 'Ley Line Entertainment'...</td>\n",
       "      <td>{'Cinematography': ['Larkin Seiple'], 'Compose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>A ticking-time-bomb insomniac and a slippery s...</td>\n",
       "      <td>139</td>\n",
       "      <td>4.27</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>drama</td>\n",
       "      <td>['Edward Norton', 'Brad Pitt', 'Helena Bonham ...</td>\n",
       "      <td>English</td>\n",
       "      <td>['Fox 2000 Pictures', 'Regency Enterprises', '...</td>\n",
       "      <td>{'Cinematography': ['Jeff Cronenweth'], 'Compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Mia, an aspiring actress, serves lattes to mov...</td>\n",
       "      <td>129</td>\n",
       "      <td>4.09</td>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>drama comedy music romance</td>\n",
       "      <td>['Ryan Gosling', 'Emma Stone', 'John Legend', ...</td>\n",
       "      <td>English</td>\n",
       "      <td>['Summit Entertainment', 'Black Label Media', ...</td>\n",
       "      <td>{'Cinematography': ['Linus Sandgren'], 'Compos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               name    year  \\\n",
       "0  1000001                             Barbie  2023.0   \n",
       "1  1000002                           Parasite  2019.0   \n",
       "2  1000003  Everything Everywhere All at Once  2022.0   \n",
       "3  1000004                         Fight Club  1999.0   \n",
       "4  1000005                         La La Land  2016.0   \n",
       "\n",
       "                                         description  minute  rating  \\\n",
       "0  Barbie and Ken are having the time of their li...     114    3.86   \n",
       "1  All unemployed, Ki-taek's family takes peculia...     133    4.56   \n",
       "2  An aging Chinese immigrant is swept up in an i...     140    4.30   \n",
       "3  A ticking-time-bomb insomniac and a slippery s...     139    4.27   \n",
       "4  Mia, an aspiring actress, serves lattes to mov...     129    4.09   \n",
       "\n",
       "                                        key  \\\n",
       "0                             Barbie (2023)   \n",
       "1                           Parasite (2019)   \n",
       "2  Everything Everywhere All at Once (2022)   \n",
       "3                         Fight Club (1999)   \n",
       "4                         La La Land (2016)   \n",
       "\n",
       "                                genre_list  \\\n",
       "0                         comedy adventure   \n",
       "1                    comedy thriller drama   \n",
       "2  science_fiction adventure comedy action   \n",
       "3                                    drama   \n",
       "4               drama comedy music romance   \n",
       "\n",
       "                                          actor_list language  \\\n",
       "0  ['Margot Robbie', 'Ryan Gosling', 'America Fer...  English   \n",
       "1  ['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...   Korean   \n",
       "2  ['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...  English   \n",
       "3  ['Edward Norton', 'Brad Pitt', 'Helena Bonham ...  English   \n",
       "4  ['Ryan Gosling', 'Emma Stone', 'John Legend', ...  English   \n",
       "\n",
       "                                         studio_list  \\\n",
       "0  ['LuckyChap Entertainment', 'Heyday Films', 'N...   \n",
       "1                                   ['Barunson E&A']   \n",
       "2  ['IAC Films', 'AGBO', 'Ley Line Entertainment'...   \n",
       "3  ['Fox 2000 Pictures', 'Regency Enterprises', '...   \n",
       "4  ['Summit Entertainment', 'Black Label Media', ...   \n",
       "\n",
       "                                           crew_dict  \n",
       "0  {'Cinematography': ['Rodrigo Prieto'], 'Compos...  \n",
       "1  {'Cinematography': ['Hong Kyung-pyo'], 'Compos...  \n",
       "2  {'Cinematography': ['Larkin Seiple'], 'Compose...  \n",
       "3  {'Cinematography': ['Jeff Cronenweth'], 'Compo...  \n",
       "4  {'Cinematography': ['Linus Sandgren'], 'Compos...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir=os.path.dirname(current_dir)\n",
    "data= pd.read_csv(os.path.join(parent_dir, 'processed_data/final_data.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from keras_preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def text_preprocess(sentence):\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers #TODO\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwords_removed = [w for w in tokenized_sentence if not w in stop_words]\n",
    "    v_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in stopwords_removed\n",
    "    ]\n",
    "    n_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\")\n",
    "        for word in v_lemmatized\n",
    "    ]\n",
    "    cleaned_sentence = ' '.join(word for word in n_lemmatized)\n",
    "    return cleaned_sentence\n",
    "\n",
    "def num_preprocess_year(value):\n",
    "    scaler = RobustScaler()\n",
    "    result = scaler.fit_transform(value)\n",
    "    return result\n",
    "\n",
    "def num_preprocess_min(value):\n",
    "    scaler = MinMaxScaler()\n",
    "    result = scaler.fit_transform(value)\n",
    "    return result\n",
    "\n",
    "def fix_data_from_csv(df):\n",
    "    df[[\"language\", \"genre_list\"]] = df[[\"language\", \"genre_list\"]].fillna(\"\")\n",
    "    return df\n",
    "\n",
    "######################### NEW INPUT #########################\n",
    "\n",
    "# changed this function ##\n",
    "def cat_processing_genre(df, column=\"genre_list\"):\n",
    "    # Initialize MultiLabelBinarizer and transform the data\n",
    "    encoder = MultiLabelBinarizer()\n",
    "    genre_df = pd.DataFrame(encoder.fit_transform(df[column].str.split(' ')),\n",
    "                                  columns=encoder.classes_,\n",
    "                                  index=df.index)\n",
    "    df = pd.concat([df, genre_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def cat_processing_lan(df, column=\"language\"):\n",
    "    \"\"\"\n",
    "    Cleans and encodes a single categorical column (e.g., language) using LabelEncoder.\n",
    "    - Keeps only the first value before delimiters (comma, slash, semicolon, pipe).\n",
    "    - Encodes categorical values into numerical labels.\n",
    "    \"\"\"\n",
    "\n",
    "    df[column] = df[column].astype(str).str.split(r\",|/|;|\\|\").str[0].str.strip()\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df[f\"{column}_encoded\"] = encoder.fit_transform(df[column])\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_eval_column(df, column_name=\"crew_dict\"):\n",
    "    \"\"\"\n",
    "    Safely converts a column containing string representations of dictionaries into actual dictionaries.\n",
    "    - If the value is already a dictionary, it remains unchanged.\n",
    "    - If the value is a valid string dictionary, it is converted using `ast.literal_eval`.\n",
    "    - If conversion fails, an empty dictionary `{}` is returned.\n",
    "    \"\"\"\n",
    "    def safe_eval(val):\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                return ast.literal_eval(val)  # Convert only if it's a valid string dictionary\n",
    "            except (ValueError, SyntaxError):\n",
    "                return {}  # Return empty dictionary if parsing fails\n",
    "        return val  # Return as is if already a dict\n",
    "\n",
    "    df[column_name] = df[column_name].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_roles(df, column_name=\"crew_dict\", roles=None):\n",
    "    \"\"\"\n",
    "    Extracts specific roles (e.g., Director, Writer) from a dictionary column.\n",
    "    Creates new columns for each role with lists of names.\n",
    "    \"\"\"\n",
    "    if roles is None:\n",
    "        roles = [\"Director\", \"Writer\", \"Cinematography\", \"Composer\"]\n",
    "\n",
    "    for role in roles:\n",
    "        df[role.lower()] = df[column_name].apply(\n",
    "            lambda x: x.get(role, []) if isinstance(x, dict) else []\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def encode_list_column_with_padding(df, column_name, padding_value=0, max_length=2):\n",
    "    \"\"\"\n",
    "    Encodes a column containing lists of categorical values (e.g., directors) and applies padding.\n",
    "    - Uses LabelEncoder to encode unique values.\n",
    "# - Pads sequences to a fixed length.\n",
    "# \"\"\"\n",
    "# # Flatten unique values for encoding\n",
    "# unique_values = sorted(set(value for sublist in df[column_name] for value in sublist))\n",
    "#\n",
    "# # Fit LabelEncoder once\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(unique_values)\n",
    "#\n",
    "# # Create mapping dictionary for faster lookup\n",
    "# encoding_map = {label: idx for idx, label in enumerate(encoder.classes_)}\n",
    "#\n",
    "# # Apply encoding efficiently\n",
    "# df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] for v in x])\n",
    "#\n",
    "# # Apply padding to ensure fixed-length sequences\n",
    "# df[f\"{column_name}_encoded_padded\"] = list(\n",
    "#     pad_sequences(df[f\"{column_name}_encoded\"], maxlen=max_length, padding='pre', value=padding_value)\n",
    "# )\n",
    "#\n",
    "# return df, len(unique_values)\n",
    "\n",
    "def data_preproc(df):\n",
    "    df = fix_data_from_csv(df)\n",
    "    df['description'] = df['description'].apply(text_preprocess)\n",
    "    df['year'] = num_preprocess_year(df[['year']])\n",
    "    df['minute'] = num_preprocess_min(df[['minute']])\n",
    "    df = cat_processing_genre(df,'genre_list') ## df equal added\n",
    "    df = cat_processing_lan(df, 'language')\n",
    "    return df\n",
    "\n",
    "def data_encode(df):\n",
    "    # Dictionary Processing\n",
    "    df = safe_eval_column(df, column_name=\"crew_dict\")\n",
    "    df = extract_roles(df, column_name=\"crew_dict\")\n",
    "\n",
    "    # Encoding list columns with padding\n",
    "    #df, director_length = encode_list_column_with_padding(df, \"director\")\n",
    "    #df, writer_length = encode_list_column_with_padding(df, \"writer\")\n",
    "    #df, cinematography_length = encode_list_column_with_padding(df, \"cinematography\")\n",
    "    #df, composer_length = encode_list_column_with_padding(df, \"composer\")\n",
    "#\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_preproc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'year', 'description', 'minute', 'rating', 'key',\n",
       "       'genre_list', 'actor_list', 'language', 'studio_list', 'crew_dict', '',\n",
       "       'action', 'adventure', 'animation', 'comedy', 'crime', 'documentary',\n",
       "       'drama', 'family', 'fantasy', 'history', 'horror', 'music', 'mystery',\n",
       "       'romance', 'science_fiction', 'thriller', 'tv_movie', 'war', 'western',\n",
       "       'language_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = data_encode(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>minute</th>\n",
       "      <th>rating</th>\n",
       "      <th>key</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>actor_list</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>science_fiction</th>\n",
       "      <th>thriller</th>\n",
       "      <th>tv_movie</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "      <th>language_encoded</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>cinematography</th>\n",
       "      <th>composer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>barbie ken time live colorful seemingly perfec...</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>3.86</td>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>comedy adventure</td>\n",
       "      <td>['Margot Robbie', 'Ryan Gosling', 'America Fer...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Greta Gerwig]</td>\n",
       "      <td>[Noah Baumbach, Greta Gerwig]</td>\n",
       "      <td>[Rodrigo Prieto]</td>\n",
       "      <td>[Mark Ronson, Andrew Wyatt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>unemployed kitaeks family take peculiar intere...</td>\n",
       "      <td>0.462312</td>\n",
       "      <td>4.56</td>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>comedy thriller drama</td>\n",
       "      <td>['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...</td>\n",
       "      <td>Korean</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>[Bong Joon-ho]</td>\n",
       "      <td>[Kim Dae-hwan, Bong Joon-ho, Han Jin-won]</td>\n",
       "      <td>[Hong Kyung-pyo]</td>\n",
       "      <td>[Jung Jae-il]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>age chinese immigrant sweep insane adventure a...</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>science_fiction adventure comedy action</td>\n",
       "      <td>['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Daniel Scheinert, Daniel Kwan]</td>\n",
       "      <td>[Daniel Kwan, Daniel Scheinert]</td>\n",
       "      <td>[Larkin Seiple]</td>\n",
       "      <td>[Ryan Lott, Rafiq Bhatia, Ian Chang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>-0.25000</td>\n",
       "      <td>tickingtimebomb insomniac slippery soap salesm...</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>4.27</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>drama</td>\n",
       "      <td>['Edward Norton', 'Brad Pitt', 'Helena Bonham ...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[David Fincher]</td>\n",
       "      <td>[Jim Uhls, Andrew Kevin Walker]</td>\n",
       "      <td>[Jeff Cronenweth]</td>\n",
       "      <td>[John King, Michael Simpson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>mia aspire actress serve latte movie star audi...</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>4.09</td>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>drama comedy music romance</td>\n",
       "      <td>['Ryan Gosling', 'Emma Stone', 'John Legend', ...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Damien Chazelle]</td>\n",
       "      <td>[Damien Chazelle]</td>\n",
       "      <td>[Linus Sandgren]</td>\n",
       "      <td>[Justin Hurwitz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406440</th>\n",
       "      <td>1941583</td>\n",
       "      <td>日本統一56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one day special investigation team suddenly be...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一56</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406441</th>\n",
       "      <td>1941584</td>\n",
       "      <td>日本統一57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hamadas death seem yuseikais problem would res...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一57</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406442</th>\n",
       "      <td>1941585</td>\n",
       "      <td>日本統一58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>makimoto tomohiro waki arimura tasuku nagaoka ...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一58</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406443</th>\n",
       "      <td>1941586</td>\n",
       "      <td>日本統一59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one day himuro yasufu motomiya tamura yoshiyuk...</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一59</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406444</th>\n",
       "      <td>1941587</td>\n",
       "      <td>日本統一60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>himuro yasufu motomiya start fight crush shimi...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一60</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406445 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                               name     year  \\\n",
       "0       1000001                             Barbie  0.50000   \n",
       "1       1000002                           Parasite  0.37500   \n",
       "2       1000003  Everything Everywhere All at Once  0.46875   \n",
       "3       1000004                         Fight Club -0.25000   \n",
       "4       1000005                         La La Land  0.28125   \n",
       "...         ...                                ...      ...   \n",
       "406440  1941583                             日本統一56      NaN   \n",
       "406441  1941584                             日本統一57      NaN   \n",
       "406442  1941585                             日本統一58      NaN   \n",
       "406443  1941586                             日本統一59      NaN   \n",
       "406444  1941587                             日本統一60      NaN   \n",
       "\n",
       "                                              description    minute  rating  \\\n",
       "0       barbie ken time live colorful seemingly perfec...  0.366834    3.86   \n",
       "1       unemployed kitaeks family take peculiar intere...  0.462312    4.56   \n",
       "2       age chinese immigrant sweep insane adventure a...  0.497487    4.30   \n",
       "3       tickingtimebomb insomniac slippery soap salesm...  0.492462    4.27   \n",
       "4       mia aspire actress serve latte movie star audi...  0.442211    4.09   \n",
       "...                                                   ...       ...     ...   \n",
       "406440  one day special investigation team suddenly be...  0.145729     NaN   \n",
       "406441  hamadas death seem yuseikais problem would res...  0.145729     NaN   \n",
       "406442  makimoto tomohiro waki arimura tasuku nagaoka ...  0.145729     NaN   \n",
       "406443  one day himuro yasufu motomiya tamura yoshiyuk...  0.150754     NaN   \n",
       "406444  himuro yasufu motomiya start fight crush shimi...  0.145729     NaN   \n",
       "\n",
       "                                             key  \\\n",
       "0                                  Barbie (2023)   \n",
       "1                                Parasite (2019)   \n",
       "2       Everything Everywhere All at Once (2022)   \n",
       "3                              Fight Club (1999)   \n",
       "4                              La La Land (2016)   \n",
       "...                                          ...   \n",
       "406440                                    日本統一56   \n",
       "406441                                    日本統一57   \n",
       "406442                                    日本統一58   \n",
       "406443                                    日本統一59   \n",
       "406444                                    日本統一60   \n",
       "\n",
       "                                     genre_list  \\\n",
       "0                              comedy adventure   \n",
       "1                         comedy thriller drama   \n",
       "2       science_fiction adventure comedy action   \n",
       "3                                         drama   \n",
       "4                    drama comedy music romance   \n",
       "...                                         ...   \n",
       "406440                                            \n",
       "406441                                            \n",
       "406442                                            \n",
       "406443                                            \n",
       "406444                                            \n",
       "\n",
       "                                               actor_list language  ...  \\\n",
       "0       ['Margot Robbie', 'Ryan Gosling', 'America Fer...  English  ...   \n",
       "1       ['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...   Korean  ...   \n",
       "2       ['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...  English  ...   \n",
       "3       ['Edward Norton', 'Brad Pitt', 'Helena Bonham ...  English  ...   \n",
       "4       ['Ryan Gosling', 'Emma Stone', 'John Legend', ...  English  ...   \n",
       "...                                                   ...      ...  ...   \n",
       "406440                                                 []  English  ...   \n",
       "406441                                                 []  English  ...   \n",
       "406442                                                 []  English  ...   \n",
       "406443                                                 []  English  ...   \n",
       "406444                                                 []  English  ...   \n",
       "\n",
       "       science_fiction thriller  tv_movie  war  western  language_encoded  \\\n",
       "0                    0        0         0    0        0                38   \n",
       "1                    0        1         0    0        0                77   \n",
       "2                    1        0         0    0        0                38   \n",
       "3                    0        0         0    0        0                38   \n",
       "4                    0        0         0    0        0                38   \n",
       "...                ...      ...       ...  ...      ...               ...   \n",
       "406440               0        0         0    0        0                38   \n",
       "406441               0        0         0    0        0                38   \n",
       "406442               0        0         0    0        0                38   \n",
       "406443               0        0         0    0        0                38   \n",
       "406444               0        0         0    0        0                38   \n",
       "\n",
       "                               director  \\\n",
       "0                        [Greta Gerwig]   \n",
       "1                        [Bong Joon-ho]   \n",
       "2       [Daniel Scheinert, Daniel Kwan]   \n",
       "3                       [David Fincher]   \n",
       "4                     [Damien Chazelle]   \n",
       "...                                 ...   \n",
       "406440                               []   \n",
       "406441                               []   \n",
       "406442                               []   \n",
       "406443                               []   \n",
       "406444                               []   \n",
       "\n",
       "                                           writer     cinematography  \\\n",
       "0                   [Noah Baumbach, Greta Gerwig]   [Rodrigo Prieto]   \n",
       "1       [Kim Dae-hwan, Bong Joon-ho, Han Jin-won]   [Hong Kyung-pyo]   \n",
       "2                 [Daniel Kwan, Daniel Scheinert]    [Larkin Seiple]   \n",
       "3                 [Jim Uhls, Andrew Kevin Walker]  [Jeff Cronenweth]   \n",
       "4                               [Damien Chazelle]   [Linus Sandgren]   \n",
       "...                                           ...                ...   \n",
       "406440                                         []                 []   \n",
       "406441                                         []                 []   \n",
       "406442                                         []                 []   \n",
       "406443                                         []                 []   \n",
       "406444                                         []                 []   \n",
       "\n",
       "                                    composer  \n",
       "0                [Mark Ronson, Andrew Wyatt]  \n",
       "1                              [Jung Jae-il]  \n",
       "2       [Ryan Lott, Rafiq Bhatia, Ian Chang]  \n",
       "3               [John King, Michael Simpson]  \n",
       "4                           [Justin Hurwitz]  \n",
       "...                                      ...  \n",
       "406440                                    []  \n",
       "406441                                    []  \n",
       "406442                                    []  \n",
       "406443                                    []  \n",
       "406444                                    []  \n",
       "\n",
       "[406445 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(data_encoded[0])\n",
    "df = data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "name                     0\n",
       "year                 15719\n",
       "description              0\n",
       "minute                   0\n",
       "rating              331222\n",
       "key                      0\n",
       "genre_list               0\n",
       "actor_list               0\n",
       "language                 0\n",
       "studio_list              0\n",
       "crew_dict            38988\n",
       "                         0\n",
       "action                   0\n",
       "adventure                0\n",
       "animation                0\n",
       "comedy                   0\n",
       "crime                    0\n",
       "documentary              0\n",
       "drama                    0\n",
       "family                   0\n",
       "fantasy                  0\n",
       "history                  0\n",
       "horror                   0\n",
       "music                    0\n",
       "mystery                  0\n",
       "romance                  0\n",
       "science_fiction          0\n",
       "thriller                 0\n",
       "tv_movie                 0\n",
       "war                      0\n",
       "western                  0\n",
       "language_encoded         0\n",
       "director                 0\n",
       "writer                   0\n",
       "cinematography           0\n",
       "composer                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample = df.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_crew = data_encoded[1]\n",
    "#dict_crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFIDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "tfidf_dim=2500\n",
    "\n",
    "def vectorize_descriptions(df, text_column):\n",
    "    \"\"\"\n",
    "    Vectorize movie descriptions using TF-IDF.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing movie descriptions.\n",
    "        text_column: The column in the DataFrame that contains descriptions.\n",
    "\n",
    "    Returns:\n",
    "        tfidf_matrix: The TF-IDF matrix.\n",
    "        vectorizer: The fitted TfidfVectorizer object (useful if needed later).\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=tfidf_dim)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[text_column])\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    return tfidf_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>barbie ken time live colorful seemingly perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>unemployed kitaeks family take peculiar intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>age chinese immigrant sweep insane adventure a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>tickingtimebomb insomniac slippery soap salesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>mia aspire actress serve latte movie star audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406440</th>\n",
       "      <td>日本統一56</td>\n",
       "      <td>one day special investigation team suddenly be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406441</th>\n",
       "      <td>日本統一57</td>\n",
       "      <td>hamadas death seem yuseikais problem would res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406442</th>\n",
       "      <td>日本統一58</td>\n",
       "      <td>makimoto tomohiro waki arimura tasuku nagaoka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406443</th>\n",
       "      <td>日本統一59</td>\n",
       "      <td>one day himuro yasufu motomiya tamura yoshiyuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406444</th>\n",
       "      <td>日本統一60</td>\n",
       "      <td>himuro yasufu motomiya start fight crush shimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406445 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             key  \\\n",
       "0                                  Barbie (2023)   \n",
       "1                                Parasite (2019)   \n",
       "2       Everything Everywhere All at Once (2022)   \n",
       "3                              Fight Club (1999)   \n",
       "4                              La La Land (2016)   \n",
       "...                                          ...   \n",
       "406440                                    日本統一56   \n",
       "406441                                    日本統一57   \n",
       "406442                                    日本統一58   \n",
       "406443                                    日本統一59   \n",
       "406444                                    日本統一60   \n",
       "\n",
       "                                              description  \n",
       "0       barbie ken time live colorful seemingly perfec...  \n",
       "1       unemployed kitaeks family take peculiar intere...  \n",
       "2       age chinese immigrant sweep insane adventure a...  \n",
       "3       tickingtimebomb insomniac slippery soap salesm...  \n",
       "4       mia aspire actress serve latte movie star audi...  \n",
       "...                                                   ...  \n",
       "406440  one day special investigation team suddenly be...  \n",
       "406441  hamadas death seem yuseikais problem would res...  \n",
       "406442  makimoto tomohiro waki arimura tasuku nagaoka ...  \n",
       "406443  one day himuro yasufu motomiya tamura yoshiyuk...  \n",
       "406444  himuro yasufu motomiya start fight crush shimi...  \n",
       "\n",
       "[406445 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = df[['key', 'description']]\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = vectorize_descriptions(text_df, 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_languages = df.language_encoded.nunique()\n",
    "num_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38]\n",
      " [77]\n",
      " [38]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]]\n"
     ]
    }
   ],
   "source": [
    "language_data = df.language_encoded\n",
    "language_data_np = np.array(language_data, dtype=np.int32).reshape(-1, 1)\n",
    "print(language_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genres= 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "genre_columns = ['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary',\n",
    "                 'drama', 'family', 'fantasy', 'history', 'horror', 'music', 'mystery',\n",
    "                 'romance', 'science_fiction', 'thriller', 'tv_movie', 'war', 'western']\n",
    "genres_data_np = df[genre_columns].values\n",
    "print(genres_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_encoder(tfidf_dim, num_languages, num_genres):\n",
    "    \"\"\"\n",
    "    Builds an encoder model that fuses:\n",
    "      - A TF-IDF vector input (continuous, shape: [tfidf_dim])\n",
    "      - A language input (integer, shape: [1])\n",
    "      - A one-hot encoded genres input (shape: [num_genres])\n",
    "\n",
    "    Parameters:\n",
    "      tfidf_dim (int): Dimensionality of the TF-IDF vector (e.g., 2500).\n",
    "      num_languages (int): Total number of language categories (max language index + 1).\n",
    "      num_genres (int): Number of genres (should be 19 for your columns).\n",
    "\n",
    "    Returns:\n",
    "      encoder_model (tf.keras.Model): A model that outputs a fused latent embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # TF-IDF Branch\n",
    "    # -------------------------\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    tfidf_dense = tf.keras.layers.Dense(128, activation='relu', name=\"tfidf_dense\")(tfidf_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Language Branch\n",
    "    # -------------------------\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    language_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_languages,\n",
    "        output_dim=8,\n",
    "        name=\"language_embedding\"\n",
    "    )(language_input)\n",
    "    language_vector = tf.keras.layers.Flatten(name=\"language_flatten\")(language_embedding)\n",
    "\n",
    "    # -------------------------\n",
    "    # Genres Branch (One-hot encoded)\n",
    "    # -------------------------\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "    # Optionally, pass the one-hot vector through a dense layer to learn a compressed representation.\n",
    "    genre_dense = tf.keras.layers.Dense(32, activation='relu', name=\"genre_dense\")(genre_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Merge Branches\n",
    "    # -------------------------\n",
    "    # Concatenate the outputs of all branches.\n",
    "    merged = tf.keras.layers.concatenate([tfidf_dense, language_vector, genre_dense], name=\"merged_features\")\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name=\"dense_1\")(merged)\n",
    "    final_embedding = tf.keras.layers.Dense(32, activation='relu', name=\"final_embedding\")(x)\n",
    "\n",
    "    # Build the encoder model\n",
    "    encoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input],\n",
    "        outputs=final_embedding\n",
    "    )\n",
    "\n",
    "    return encoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_autoencoder(tfidf_dim, num_languages, num_genres):\n",
    "    \"\"\"\n",
    "    Builds an autoencoder that uses:\n",
    "      - The encoder from build_encoder to produce a 32-d latent embedding.\n",
    "      - Three decoder branches to reconstruct:\n",
    "          A. The original TF-IDF vector.\n",
    "          B. The language (as a probability distribution over num_languages).\n",
    "          C. The one-hot encoded genres vector.\n",
    "\n",
    "    The autoencoder is compiled with MSE loss for TF-IDF, sparse categorical crossentropy for language,\n",
    "    and binary crossentropy for genres.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the inputs (they will be passed to both encoder and as targets later)\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "\n",
    "    # Build the encoder and get the latent representation.\n",
    "    encoder = build_encoder(tfidf_dim, num_languages, num_genres)\n",
    "    latent = encoder([tfidf_input, language_input, genre_input])\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for TF-IDF reconstruction\n",
    "    # -------------------------\n",
    "    decoder_tfidf = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_tfidf_dense\")(latent)\n",
    "    tfidf_output = tf.keras.layers.Dense(tfidf_dim, activation='relu', name=\"tfidf_output\")(decoder_tfidf)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Language reconstruction\n",
    "    # -------------------------\n",
    "    decoder_language = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_language_dense\")(latent)\n",
    "    # Output is a probability distribution over languages\n",
    "    language_output = tf.keras.layers.Dense(num_languages, activation='softmax', name=\"language_output\")(decoder_language)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Genres reconstruction\n",
    "    # -------------------------\n",
    "    decoder_genre = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_genre_dense\")(latent)\n",
    "    # For multi-label, we use sigmoid activation; if it's strictly one-hot, you could use softmax.\n",
    "    genre_output = tf.keras.layers.Dense(num_genres, activation='sigmoid', name=\"genre_output\")(decoder_genre)\n",
    "\n",
    "    # Build the autoencoder model.\n",
    "    autoencoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input],\n",
    "        outputs=[tfidf_output, language_output, genre_output],\n",
    "        name=\"autoencoder\"\n",
    "    )\n",
    "\n",
    "    # Compile the autoencoder:\n",
    "    # - For TF-IDF, we use mean squared error.\n",
    "    # - For language, we use sparse categorical crossentropy (the target should be an integer).\n",
    "    # - For genres, binary crossentropy is appropriate for multi-label reconstruction.\n",
    "    autoencoder_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'tfidf_output': 'mse',\n",
    "            'language_output': 'sparse_categorical_crossentropy',\n",
    "            'genre_output': 'binary_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'tfidf_output': 1.0,\n",
    "            'language_output': 1.0,\n",
    "            'genre_output': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return autoencoder_model, encoder\n",
    "\n",
    "# Example usage:\n",
    "tfidf_dim = 2500      # Dimensionality of your TF-IDF vectors\n",
    "num_languages = 172   # For example, if your full dataset has 172 unique languages (0..171)\n",
    "num_genres = 19       # One column per genre: action, adventure, ..., western\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " tfidf_input (InputLayer)       [(None, 2500)]       0           []                               \n",
      "                                                                                                  \n",
      " language_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " genre_input (InputLayer)       [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 32)           335040      ['tfidf_input[0][0]',            \n",
      "                                                                  'language_input[0][0]',         \n",
      "                                                                  'genre_input[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_tfidf_dense (Dense)    (None, 64)           2112        ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " decoder_language_dense (Dense)  (None, 16)          528         ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " decoder_genre_dense (Dense)    (None, 16)           528         ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " tfidf_output (Dense)           (None, 2500)         162500      ['decoder_tfidf_dense[0][0]']    \n",
      "                                                                                                  \n",
      " language_output (Dense)        (None, 172)          2924        ['decoder_language_dense[0][0]'] \n",
      "                                                                                                  \n",
      " genre_output (Dense)           (None, 19)           323         ['decoder_genre_dense[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 503,955\n",
      "Trainable params: 503,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model, encoder_model = build_autoencoder(tfidf_dim, num_languages, num_genres)\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 21:00:11.556632: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25403/25403 [==============================] - 75s 3ms/step - loss: 0.1616 - tfidf_output_loss: 3.9912e-04 - language_output_loss: 0.1318 - genre_output_loss: 0.0294\n",
      "Epoch 2/10\n",
      "25403/25403 [==============================] - 70s 3ms/step - loss: 0.0254 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0187 - genre_output_loss: 0.0062\n",
      "Epoch 3/10\n",
      "25403/25403 [==============================] - 66s 3ms/step - loss: 0.0161 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0114 - genre_output_loss: 0.0043\n",
      "Epoch 4/10\n",
      "25403/25403 [==============================] - 62s 2ms/step - loss: 0.0133 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0095 - genre_output_loss: 0.0034\n",
      "Epoch 5/10\n",
      "25403/25403 [==============================] - 65s 3ms/step - loss: 0.0108 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0076 - genre_output_loss: 0.0027\n",
      "Epoch 6/10\n",
      "25403/25403 [==============================] - 61s 2ms/step - loss: 0.0097 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0069 - genre_output_loss: 0.0024\n",
      "Epoch 7/10\n",
      "25403/25403 [==============================] - 58s 2ms/step - loss: 0.0094 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0069 - genre_output_loss: 0.0021\n",
      "Epoch 8/10\n",
      "25403/25403 [==============================] - 54s 2ms/step - loss: 0.0087 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0063 - genre_output_loss: 0.0020\n",
      "Epoch 9/10\n",
      "25403/25403 [==============================] - 56s 2ms/step - loss: 0.0083 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0061 - genre_output_loss: 0.0019\n",
      "Epoch 10/10\n",
      "25403/25403 [==============================] - 58s 2ms/step - loss: 0.0079 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0057 - genre_output_loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x54a7c30d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = autoencoder_model.fit(\n",
    "    x=[tfidf_array, language_data_np, genres_data_np],\n",
    "    y=[tfidf_array, language_data_np, genres_data_np],\n",
    "    batch_size=16,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12702/12702 [==============================] - 15s 1ms/step\n",
      "Latent embeddings shape: (406445, 32)\n"
     ]
    }
   ],
   "source": [
    "# xtract latent embeddings using the encoder model.\n",
    "latent_embeddings = encoder_model.predict([tfidf_array, language_data_np, genres_data_np])\n",
    "print(\"Latent embeddings shape:\", latent_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = os.path.join(parent_dir, \"processed_data\", \"latent_embeddings.pkl\")\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(latent_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a KNN model for similarity search using the latent embeddings.\n",
    "n_neighbors = 5\n",
    "knn_model = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine')\n",
    "knn_model.fit(latent_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found movie 'The bourne identity'.\n",
      "Recommended Movies:\n",
      "- Conspiracy Theory (Distance: 0.000006)\n",
      "- The Stranger (Distance: 0.000006)\n",
      "- Oldboy (Distance: 0.000006)\n",
      "- The Bourne Ultimatum (Distance: 0.000006)\n",
      "- Flashpoint (Distance: 0.000006)\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The bourne identity\"  # Example input\n",
    "\n",
    "# Convert both the user input and the DataFrame names to lowercase for case-insensitive matching.\n",
    "matched_rows = df[df[\"name\"].str.lower() == user_input.lower()]\n",
    "\n",
    "if matched_rows.empty:\n",
    "    print(\"Movie not found.\")\n",
    "else:\n",
    "    # Get the first matching index (handle multiple matches as needed)\n",
    "    sample_index = matched_rows.index[0]\n",
    "    print(f\"Found movie '{user_input}'.\")\n",
    "\n",
    "    # Retrieve KNN results.\n",
    "    distances, indices = knn_model.kneighbors(latent_embeddings[sample_index].reshape(1, -1))\n",
    "\n",
    "    # Convert to 1D arrays.\n",
    "    indices = indices.flatten()\n",
    "    distances = distances.flatten()\n",
    "\n",
    "    # Filter out the queried movie (its index should match sample_index).\n",
    "    filtered_recs = [(idx, dist) for idx, dist in zip(indices, distances) if idx != sample_index]\n",
    "\n",
    "    # If the filtered recommendations list is empty or too short, you may want to handle that.\n",
    "    if not filtered_recs:\n",
    "        print(\"No recommendations found after filtering out the queried movie.\")\n",
    "    else:\n",
    "        print(\"Recommended Movies:\")\n",
    "        for idx, dist in filtered_recs:\n",
    "            movie_name = df.loc[idx, \"name\"]\n",
    "            print(f\"- {movie_name} (Distance: {dist:.6f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def encode_list_column_with_padding(df, column_name, padding_value=0, max_length=2, reserve_zero=True):\n",
    "    \"\"\"\n",
    "    Encodes a column containing lists of categorical values (e.g., directors) and applies padding.\n",
    "    - Uses LabelEncoder to encode unique values.\n",
    "    - Optionally offsets encoding so that 0 is reserved for padding (i.e., valid values start at 1).\n",
    "    - Pads sequences to a fixed length.\n",
    "\n",
    "    Parameters:\n",
    "      df: pandas DataFrame.\n",
    "      column_name: Name of the column containing lists to be encoded.\n",
    "      padding_value: The value used for padding (default is 0).\n",
    "      max_length: The fixed sequence length after padding.\n",
    "      reserve_zero: If True, adds 1 to each encoded value so that 0 can be reserved exclusively for padding.\n",
    "\n",
    "    Returns:\n",
    "      The modified DataFrame and the number of unique encoded values (adjusted for offset if reserve_zero is True).\n",
    "    \"\"\"\n",
    "    # Flatten unique values for encoding\n",
    "    unique_values = sorted(set(value for sublist in df[column_name] for value in sublist))\n",
    "\n",
    "    # Fit LabelEncoder on the unique values\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(unique_values)\n",
    "\n",
    "    # Create a mapping dictionary for faster lookup\n",
    "    encoding_map = {label: idx for idx, label in enumerate(encoder.classes_)}\n",
    "\n",
    "    if reserve_zero:\n",
    "        # Offset each encoded value by 1, so that 0 is reserved for padding.\n",
    "        df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] + 1 for v in x])\n",
    "        # Adjust the number of unique values accordingly.\n",
    "        num_unique = len(unique_values) + 1\n",
    "    else:\n",
    "        df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] for v in x])\n",
    "        num_unique = len(unique_values)\n",
    "\n",
    "    # Apply padding to ensure fixed-length sequences.\n",
    "    df[f\"{column_name}_encoded_padded\"] = list(\n",
    "        pad_sequences(df[f\"{column_name}_encoded\"], maxlen=max_length, padding='pre', value=padding_value)\n",
    "    )\n",
    "\n",
    "    return df, num_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique directors: 4733\n"
     ]
    }
   ],
   "source": [
    "df, num_directors = encode_list_column_with_padding(df_sample, \"director\")\n",
    "# Now, df contains a new column \"director_encoded_padded\" with a fixed-length sequence.\n",
    "print(\"Number of unique directors:\", num_directors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>minute</th>\n",
       "      <th>rating</th>\n",
       "      <th>key</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>actor_list</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>tv_movie</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "      <th>language_encoded</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>cinematography</th>\n",
       "      <th>composer</th>\n",
       "      <th>director_encoded</th>\n",
       "      <th>director_encoded_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260673</th>\n",
       "      <td>1412093</td>\n",
       "      <td>Everything is Forever</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>documentary nenad bach rock star croatia make ...</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Everything is Forever (2014)</td>\n",
       "      <td>music documentary</td>\n",
       "      <td>[\"Michael O'Keefe\"]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Victor Zimet]</td>\n",
       "      <td>[Stephanie Silber]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4444]</td>\n",
       "      <td>[0, 4444]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162056</th>\n",
       "      <td>1219351</td>\n",
       "      <td>Overdrive</td>\n",
       "      <td>-0.31250</td>\n",
       "      <td>reckless racecar driver gary stricker find wom...</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overdrive (1997)</td>\n",
       "      <td>action</td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Lev L. Spiro]</td>\n",
       "      <td>[Malcolm Stephens]</td>\n",
       "      <td>[Christopher Baffa]</td>\n",
       "      <td>[Nigel Holton]</td>\n",
       "      <td>[2594]</td>\n",
       "      <td>[0, 2594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186456</th>\n",
       "      <td>1261610</td>\n",
       "      <td>Three Wise Fools</td>\n",
       "      <td>-2.62500</td>\n",
       "      <td>sydney fairchild daughter woman love three bac...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three Wise Fools (1923)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>['Claude Gillingwater', 'Eleanor Boardman', 'J...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[King Vidor]</td>\n",
       "      <td>[June Mathis, King Vidor, James O'Hanlon, John...</td>\n",
       "      <td>[Charles Van Enger, Paul Ivano]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2439]</td>\n",
       "      <td>[0, 2439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101026</th>\n",
       "      <td>1126651</td>\n",
       "      <td>Family Party</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>th birthday famous piano virtuoso hannes westh...</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Party (2015)</td>\n",
       "      <td>family drama</td>\n",
       "      <td>['Günther Maria Halmer', 'Hannelore Elsner', '...</td>\n",
       "      <td>German</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>[Lars Kraume]</td>\n",
       "      <td>[Andrea Stoll, Martin Rauhaus]</td>\n",
       "      <td>[Jens Harant]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2529]</td>\n",
       "      <td>[0, 2529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166703</th>\n",
       "      <td>1227125</td>\n",
       "      <td>Robin Hood of Monterey</td>\n",
       "      <td>-1.87500</td>\n",
       "      <td>eduardo belmonte overhear new stepmother maria...</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robin Hood of Monterey (1947)</td>\n",
       "      <td>romance western</td>\n",
       "      <td>['Gilbert Roland', 'Chris-Pin Martin', 'Evelyn...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[Christy Cabanne]</td>\n",
       "      <td>[Bennett Cohen]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[769]</td>\n",
       "      <td>[0, 769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238339</th>\n",
       "      <td>1362428</td>\n",
       "      <td>Merijntje Gijzen's Boyhood</td>\n",
       "      <td>-2.21875</td>\n",
       "      <td>merijntje gijzen small boy grow brabant south ...</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merijntje Gijzen's Boyhood (1936)</td>\n",
       "      <td></td>\n",
       "      <td>['Aaf Bouber', 'Matthieu van Eysden', 'Kees Br...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[Kurt Gerron]</td>\n",
       "      <td>[A.M. de Jong]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Max Tak]</td>\n",
       "      <td>[2496]</td>\n",
       "      <td>[0, 2496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77271</th>\n",
       "      <td>1093686</td>\n",
       "      <td>People Who Talk to Plushies Are Kind</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>sophomore university student nanamori meet mug...</td>\n",
       "      <td>0.341709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>People Who Talk to Plushies Are Kind (2023)</td>\n",
       "      <td>drama</td>\n",
       "      <td>[]</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>[Yurina Kaneko]</td>\n",
       "      <td>[Yurina Kaneko, Suzuyuki Kaneko, Ao Omae]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4664]</td>\n",
       "      <td>[0, 4664]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100841</th>\n",
       "      <td>1126400</td>\n",
       "      <td>The Big Sweat</td>\n",
       "      <td>-0.50000</td>\n",
       "      <td>excon release jail return home become immediat...</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Big Sweat (1991)</td>\n",
       "      <td>action</td>\n",
       "      <td>[\"Robert Z'Dar\"]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Ulli Lommel]</td>\n",
       "      <td>[Ulli Lommel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4390]</td>\n",
       "      <td>[0, 4390]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122073</th>\n",
       "      <td>1156894</td>\n",
       "      <td>Walking My Baby Back Home</td>\n",
       "      <td>-1.68750</td>\n",
       "      <td>young man wealthy new york family pursue caree...</td>\n",
       "      <td>0.271357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walking My Baby Back Home (1953)</td>\n",
       "      <td>comedy music</td>\n",
       "      <td>[\"Donald O'Connor\", 'Janet Leigh', 'Buddy Hack...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Lloyd Bacon]</td>\n",
       "      <td>[Don McGuire, Oscar Brodney]</td>\n",
       "      <td>[Irving Glassberg]</td>\n",
       "      <td>[Henry Mancini]</td>\n",
       "      <td>[2645]</td>\n",
       "      <td>[0, 2645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65425</th>\n",
       "      <td>1077802</td>\n",
       "      <td>Nata per te</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>alba syndrome leave hospital bear thirty famil...</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>3.41</td>\n",
       "      <td>Nata per te (2023)</td>\n",
       "      <td>drama</td>\n",
       "      <td>['Teresa Saponangelo', 'Barbora Bobuľová', 'An...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>[Fabio Mollo]</td>\n",
       "      <td>[Giulia Calenda, Furio Andreotti, Fabio Mollo]</td>\n",
       "      <td>[Claudio Cofrancesco]</td>\n",
       "      <td>[Giorgio Giampà]</td>\n",
       "      <td>[1265]</td>\n",
       "      <td>[0, 1265]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  name     year  \\\n",
       "260673  1412093                 Everything is Forever  0.21875   \n",
       "162056  1219351                             Overdrive -0.31250   \n",
       "186456  1261610                      Three Wise Fools -2.62500   \n",
       "101026  1126651                          Family Party  0.25000   \n",
       "166703  1227125                Robin Hood of Monterey -1.87500   \n",
       "...         ...                                   ...      ...   \n",
       "238339  1362428            Merijntje Gijzen's Boyhood -2.21875   \n",
       "77271   1093686  People Who Talk to Plushies Are Kind  0.50000   \n",
       "100841  1126400                         The Big Sweat -0.50000   \n",
       "122073  1156894             Walking My Baby Back Home -1.68750   \n",
       "65425   1077802                           Nata per te  0.50000   \n",
       "\n",
       "                                              description    minute  rating  \\\n",
       "260673  documentary nenad bach rock star croatia make ...  0.231156     NaN   \n",
       "162056  reckless racecar driver gary stricker find wom...  0.256281     NaN   \n",
       "186456  sydney fairchild daughter woman love three bac...  0.145729     NaN   \n",
       "101026  th birthday famous piano virtuoso hannes westh...  0.251256     NaN   \n",
       "166703  eduardo belmonte overhear new stepmother maria...  0.075377     NaN   \n",
       "...                                                   ...       ...     ...   \n",
       "238339  merijntje gijzen small boy grow brabant south ...  0.256281     NaN   \n",
       "77271   sophomore university student nanamori meet mug...  0.341709     NaN   \n",
       "100841  excon release jail return home become immediat...  0.226131     NaN   \n",
       "122073  young man wealthy new york family pursue caree...  0.271357     NaN   \n",
       "65425   alba syndrome leave hospital bear thirty famil...  0.361809    3.41   \n",
       "\n",
       "                                                key         genre_list  \\\n",
       "260673                 Everything is Forever (2014)  music documentary   \n",
       "162056                             Overdrive (1997)             action   \n",
       "186456                      Three Wise Fools (1923)             comedy   \n",
       "101026                          Family Party (2015)       family drama   \n",
       "166703                Robin Hood of Monterey (1947)    romance western   \n",
       "...                                             ...                ...   \n",
       "238339            Merijntje Gijzen's Boyhood (1936)                      \n",
       "77271   People Who Talk to Plushies Are Kind (2023)              drama   \n",
       "100841                         The Big Sweat (1991)             action   \n",
       "122073             Walking My Baby Back Home (1953)       comedy music   \n",
       "65425                            Nata per te (2023)              drama   \n",
       "\n",
       "                                               actor_list  language  ...  \\\n",
       "260673                                [\"Michael O'Keefe\"]   English  ...   \n",
       "162056                                                 []   English  ...   \n",
       "186456  ['Claude Gillingwater', 'Eleanor Boardman', 'J...            ...   \n",
       "101026  ['Günther Maria Halmer', 'Hannelore Elsner', '...    German  ...   \n",
       "166703  ['Gilbert Roland', 'Chris-Pin Martin', 'Evelyn...   English  ...   \n",
       "...                                                   ...       ...  ...   \n",
       "238339  ['Aaf Bouber', 'Matthieu van Eysden', 'Kees Br...     Dutch  ...   \n",
       "77271                                                  []  Japanese  ...   \n",
       "100841                                   [\"Robert Z'Dar\"]   English  ...   \n",
       "122073  [\"Donald O'Connor\", 'Janet Leigh', 'Buddy Hack...   English  ...   \n",
       "65425   ['Teresa Saponangelo', 'Barbora Bobuľová', 'An...   Italian  ...   \n",
       "\n",
       "       tv_movie war  western  language_encoded           director  \\\n",
       "260673        0   0        0                38     [Victor Zimet]   \n",
       "162056        0   0        0                38     [Lev L. Spiro]   \n",
       "186456        0   0        0                 0       [King Vidor]   \n",
       "101026        0   0        0                49      [Lars Kraume]   \n",
       "166703        0   0        1                38  [Christy Cabanne]   \n",
       "...         ...  ..      ...               ...                ...   \n",
       "238339        0   0        0                35      [Kurt Gerron]   \n",
       "77271         0   0        0                66    [Yurina Kaneko]   \n",
       "100841        0   0        0                38      [Ulli Lommel]   \n",
       "122073        0   0        0                38      [Lloyd Bacon]   \n",
       "65425         0   0        0                65      [Fabio Mollo]   \n",
       "\n",
       "                                                   writer  \\\n",
       "260673                                 [Stephanie Silber]   \n",
       "162056                                 [Malcolm Stephens]   \n",
       "186456  [June Mathis, King Vidor, James O'Hanlon, John...   \n",
       "101026                     [Andrea Stoll, Martin Rauhaus]   \n",
       "166703                                    [Bennett Cohen]   \n",
       "...                                                   ...   \n",
       "238339                                     [A.M. de Jong]   \n",
       "77271           [Yurina Kaneko, Suzuyuki Kaneko, Ao Omae]   \n",
       "100841                                      [Ulli Lommel]   \n",
       "122073                       [Don McGuire, Oscar Brodney]   \n",
       "65425      [Giulia Calenda, Furio Andreotti, Fabio Mollo]   \n",
       "\n",
       "                         cinematography          composer  director_encoded  \\\n",
       "260673                               []                []            [4444]   \n",
       "162056              [Christopher Baffa]    [Nigel Holton]            [2594]   \n",
       "186456  [Charles Van Enger, Paul Ivano]                []            [2439]   \n",
       "101026                    [Jens Harant]                []            [2529]   \n",
       "166703                               []                []             [769]   \n",
       "...                                 ...               ...               ...   \n",
       "238339                               []         [Max Tak]            [2496]   \n",
       "77271                                []                []            [4664]   \n",
       "100841                               []                []            [4390]   \n",
       "122073               [Irving Glassberg]   [Henry Mancini]            [2645]   \n",
       "65425             [Claudio Cofrancesco]  [Giorgio Giampà]            [1265]   \n",
       "\n",
       "        director_encoded_padded  \n",
       "260673                [0, 4444]  \n",
       "162056                [0, 2594]  \n",
       "186456                [0, 2439]  \n",
       "101026                [0, 2529]  \n",
       "166703                 [0, 769]  \n",
       "...                         ...  \n",
       "238339                [0, 2496]  \n",
       "77271                 [0, 4664]  \n",
       "100841                [0, 4390]  \n",
       "122073                [0, 2645]  \n",
       "65425                 [0, 1265]  \n",
       "\n",
       "[5000 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF, Language, Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_autoencoder(tfidf_dim, num_languages, num_directors):\n",
    "    \"\"\"\n",
    "    Builds and compiles a multi-branch autoencoder model that takes as input:\n",
    "      - A TF-IDF vector (continuous, shape: [tfidf_dim])\n",
    "      - A language label (integer, shape: [1])\n",
    "      - A padded director sequence (integer, shape: [2])\n",
    "\n",
    "    The model outputs reconstructed versions of these inputs:\n",
    "      - TF-IDF reconstruction (using MSE loss)\n",
    "      - Language reconstruction (as a classification over num_languages with sparse categorical crossentropy)\n",
    "      - Director reconstruction (as a sequence of categorical distributions over num_directors)\n",
    "\n",
    "    Parameters:\n",
    "      tfidf_dim (int): Dimensionality of the TF-IDF vectors.\n",
    "      num_languages (int): Number of unique language labels.\n",
    "      num_directors (int): Number of unique director tokens (including padding if 0 is reserved).\n",
    "\n",
    "    Returns:\n",
    "      autoencoder (tf.keras.Model): The compiled autoencoder model.\n",
    "    \"\"\"\n",
    "\n",
    "    # ====================\n",
    "    # Encoder Architecture\n",
    "    # ====================\n",
    "\n",
    "    # 1. TF-IDF branch (continuous input)\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    tfidf_dense = tf.keras.layers.Dense(128, activation='relu', name=\"tfidf_dense\")(tfidf_input)\n",
    "\n",
    "    # 2. Language branch (categorical input as integer)\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    language_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_languages,\n",
    "        output_dim=8,\n",
    "        name=\"language_embedding\"\n",
    "    )(language_input)\n",
    "    language_vector = tf.keras.layers.Flatten(name=\"language_flatten\")(language_embedding)\n",
    "\n",
    "    # 3. Director branch (padded sequence, e.g., length=2)\n",
    "    director_input = tf.keras.layers.Input(shape=(2,), name=\"director_input\")\n",
    "    director_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_directors,      # Ensure this covers your director encoding (with padding)\n",
    "        output_dim=16,                # Adjust the embedding dimension as needed\n",
    "        mask_zero=True,               # Use mask_zero=True if 0 is reserved for padding\n",
    "        name=\"director_embedding\"\n",
    "    )(director_input)\n",
    "    # Aggregate the director embeddings (e.g., by average pooling)\n",
    "    director_vector = tf.keras.layers.GlobalAveragePooling1D(name=\"director_pooling\")(director_embedding)\n",
    "\n",
    "    # Merge all branches into a joint representation\n",
    "    merged = tf.keras.layers.concatenate([tfidf_dense, language_vector, director_vector],\n",
    "                                           name=\"merged_features\")\n",
    "    dense = tf.keras.layers.Dense(64, activation='relu', name=\"dense\")(merged)\n",
    "    # The final encoder output (latent representation)\n",
    "    final_embedding = tf.keras.layers.Dense(32, activation='relu', name=\"final_embedding\")(dense)\n",
    "\n",
    "    # ====================\n",
    "    # Decoder Architecture\n",
    "    # ====================\n",
    "\n",
    "    # A. TF-IDF Decoder: reconstruct the original TF-IDF vector.\n",
    "    decoder_dense_tfidf = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_dense_tfidf\")(final_embedding)\n",
    "    tfidf_output = tf.keras.layers.Dense(tfidf_dim, activation='relu', name=\"tfidf_output\")(decoder_dense_tfidf)\n",
    "\n",
    "    # B. Language Decoder: reconstruct the language label.\n",
    "    decoder_dense_lang = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_dense_lang\")(final_embedding)\n",
    "    language_output = tf.keras.layers.Dense(num_languages, activation='softmax', name=\"language_output\")(decoder_dense_lang)\n",
    "\n",
    "    # C. Director Decoder: reconstruct the padded director sequence.\n",
    "    # We want to predict 2 directors (each as a categorical distribution over num_directors)\n",
    "    decoder_dense_dir = tf.keras.layers.Dense(32, activation='relu', name=\"decoder_dense_dir\")(final_embedding)\n",
    "    # Produce 2 * num_directors outputs, then reshape into a sequence of length 2.\n",
    "    director_output_dense = tf.keras.layers.Dense(2 * num_directors, activation='softmax', name=\"director_output_dense\")(decoder_dense_dir)\n",
    "    director_output = tf.keras.layers.Reshape((2, num_directors), name=\"director_output\")(director_output_dense)\n",
    "\n",
    "    # ====================\n",
    "    # Assemble the Autoencoder\n",
    "    # ====================\n",
    "\n",
    "    autoencoder = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, director_input],\n",
    "        outputs=[tfidf_output, language_output, director_output]\n",
    "    )\n",
    "\n",
    "    # Compile the model with appropriate losses for each branch.\n",
    "    # - For TF-IDF, use Mean Squared Error (MSE).\n",
    "    # - For language and director outputs, use sparse categorical crossentropy.\n",
    "    autoencoder.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'tfidf_output': 'mse',\n",
    "            'language_output': 'sparse_categorical_crossentropy',\n",
    "            'director_output': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'tfidf_output': 1.0,\n",
    "            'language_output': 1.0,\n",
    "            'director_output': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " language_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " director_input (InputLayer)    [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tfidf_input (InputLayer)       [(None, 2500)]       0           []                               \n",
      "                                                                                                  \n",
      " language_embedding (Embedding)  (None, 1, 8)        640         ['language_input[0][0]']         \n",
      "                                                                                                  \n",
      " director_embedding (Embedding)  (None, 2, 16)       75728       ['director_input[0][0]']         \n",
      "                                                                                                  \n",
      " tfidf_dense (Dense)            (None, 128)          320128      ['tfidf_input[0][0]']            \n",
      "                                                                                                  \n",
      " language_flatten (Flatten)     (None, 8)            0           ['language_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " director_pooling (GlobalAverag  (None, 16)          0           ['director_embedding[0][0]']     \n",
      " ePooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " merged_features (Concatenate)  (None, 152)          0           ['tfidf_dense[0][0]',            \n",
      "                                                                  'language_flatten[0][0]',       \n",
      "                                                                  'director_pooling[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           9792        ['merged_features[0][0]']        \n",
      "                                                                                                  \n",
      " final_embedding (Dense)        (None, 32)           2080        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " decoder_dense_dir (Dense)      (None, 32)           1056        ['final_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_dense_tfidf (Dense)    (None, 64)           2112        ['final_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_dense_lang (Dense)     (None, 16)           528         ['final_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " director_output_dense (Dense)  (None, 9466)         312378      ['decoder_dense_dir[0][0]']      \n",
      "                                                                                                  \n",
      " tfidf_output (Dense)           (None, 2500)         162500      ['decoder_dense_tfidf[0][0]']    \n",
      "                                                                                                  \n",
      " language_output (Dense)        (None, 80)           1360        ['decoder_dense_lang[0][0]']     \n",
      "                                                                                                  \n",
      " director_output (Reshape)      (None, 2, 4733)      0           ['director_output_dense[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 888,302\n",
      "Trainable params: 888,302\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "tfidf_dim = 2500\n",
    "num_languages = num_languages\n",
    "num_directors = num_directors\n",
    "\n",
    "# Build the autoencoder model\n",
    "autoencoder_model = build_autoencoder(tfidf_dim, num_languages, num_directors)\n",
    "\n",
    "# Display the model summary\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_data = df_sample.language_encoded\n",
    "director_data = df_sample.director_encoded_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38]\n",
      " [38]\n",
      " [ 0]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [65]]\n"
     ]
    }
   ],
   "source": [
    "language_data_np = np.array(language_data, dtype=np.int32)\n",
    "language_data_np = language_data_np.reshape(-1, 1)\n",
    "print(language_data_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director data shape: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "director_data_np = np.array(director_data.tolist(), dtype=np.int32)\n",
    "print(\"Director data shape:\", director_data_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtfidf_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_data_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirector_data_np\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtfidf_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_data_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirector_data_np\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "autoencoder_model.fit(\n",
    "    x=[tfidf_array, language_data_np, director_data_np],\n",
    "    y=[tfidf_array, language_data_np, director_data_np],\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means and Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚀 Full Workflow for K-Means + KNN Movie Recommendation\n",
    "This approach:\n",
    "\n",
    "Prepares data (TF-IDF + numerical/categorical features) ✅\n",
    "Clusters movies using K-Means ✅\n",
    "Applies KNN only within the closest cluster ✅\n",
    "Returns top-K similar movies efficiently ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use sparse instead of df**\n",
    "✅ Keeps TF-IDF sparse (NO toarray() conversion) → Saves RAM\n",
    "✅ Uses hstack() for memory-efficient feature merging\n",
    "✅ Clusters movies using MiniBatchKMeans to reduce computation\n",
    "✅ Limits KNN search to relevant clusters → 10x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def expand_list_columns(df, list_columns, max_elements=2):\n",
    "    \"\"\"\n",
    "    Expand list-type columns into separate numerical columns.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame\n",
    "        list_columns: List of column names that contain lists\n",
    "        max_elements: Number of elements to extract from each list (default=2)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with expanded columns.\n",
    "    \"\"\"\n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [0] * max_elements)  # Handle NaNs\n",
    "        for i in range(max_elements):\n",
    "            df[f'{col}_{i}'] = df[col].apply(lambda x: x[i] if len(x) > i else 0)  # Extract element i\n",
    "        df.drop(columns=[col], inplace=True)  # Drop original column\n",
    "    return df\n",
    "\n",
    "def preprocess_features_sparse(tfidf_matrix, X):\n",
    "    \"\"\"\n",
    "    Process and concatenate TF-IDF features with numerical/categorical features (sparse version).\n",
    "    \"\"\"\n",
    "    # ✅ Keep TF-IDF sparse\n",
    "    tfidf_sparse = csr_matrix(tfidf_matrix)  # No conversion to dense!\n",
    "\n",
    "    # ✅ Drop 'key' column before merging\n",
    "    X_numeric = X.drop(columns=['key', 'name'])\n",
    "\n",
    "    # ✅ Convert list-type columns into separate numerical columns\n",
    "    list_columns = [\n",
    "        'director_encoded_padded', 'writer_encoded_padded',\n",
    "        'cinematography_encoded_padded', 'composer_encoded_padded'\n",
    "    ]\n",
    "    X_numeric = expand_list_columns(X_numeric, list_columns)\n",
    "\n",
    "    # ✅ Convert X_numeric to sparse matrix\n",
    "    X_numeric_sparse = csr_matrix(X_numeric.values)\n",
    "\n",
    "    # ✅ Concatenate using Scipy `hstack()` (efficient!)\n",
    "    X_final = hstack([tfidf_sparse, X_numeric_sparse])\n",
    "\n",
    "    return X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def cluster_movies_kmeans_sparse(X_final, n_clusters=200):\n",
    "    \"\"\"\n",
    "    Cluster movies using K-Means on sparse matrix.\n",
    "    \"\"\"\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=1024)\n",
    "    clusters = kmeans.fit_predict(X_final)\n",
    "\n",
    "    return kmeans, clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies_kmeans_knn_sparse(movie_name, X_final, df, kmeans, name_column, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Find similar movies using KNN within the assigned cluster from K-Means (Sparse Matrix version).\n",
    "    Handles case-insensitive movie name search.\n",
    "    \"\"\"\n",
    "    # ✅ Convert movie names in DataFrame to lowercase for case-insensitive search\n",
    "    df['lowercase_name'] = df[name_column].str.lower()\n",
    "\n",
    "    # ✅ Convert input movie name to lowercase\n",
    "    movie_name_lower = movie_name.lower()\n",
    "\n",
    "    # ✅ Verify movie exists (case-insensitive search)\n",
    "    if movie_name_lower not in df['lowercase_name'].values:\n",
    "        raise ValueError(f\"Movie '{movie_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # ✅ Get index of input movie\n",
    "    idx = df[df['lowercase_name'] == movie_name_lower].index[0]\n",
    "\n",
    "    # ✅ Predict the cluster for the input movie\n",
    "    movie_cluster = kmeans.predict(X_final[idx].reshape(1, -1))[0]\n",
    "\n",
    "    # ✅ Get indices of movies in the same cluster\n",
    "    cluster_indices = df[df[\"cluster\"] == movie_cluster].index\n",
    "\n",
    "    # ✅ Apply KNN only within the cluster\n",
    "    knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn_model.fit(X_final[cluster_indices])\n",
    "\n",
    "    # ✅ Find K-nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors(X_final[idx].reshape(1, -1), n_neighbors=n_neighbors + 1)\n",
    "\n",
    "    return df.iloc[indices.flatten()[1:]][name_column].tolist()  # Exclude input movie itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = preprocess_features_sparse(tfidf_matrix, X)  # This should NOT crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aybikealkan/.pyenv/versions/3.10.6/envs/movie_picker/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "kmeans, clusters = cluster_movies_kmeans_sparse(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Movie: The Wolf of Wall Street\n",
      "Similar Movie: Requiem for a Dream\n",
      "Similar Movie: Easy A\n",
      "Similar Movie: Bring It On\n",
      "Similar Movie: Zoolander\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_similar_movies_kmeans_knn_sparse(\"the bourne ultimatum\", X_final, X, kmeans, \"name\", n_neighbors=5)\n",
    "\n",
    "for movie in recommendations:\n",
    "    print(f\"Similar Movie: {movie}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'minute', 'key', 'action', 'adventure', 'animation', 'comedy',\n",
       "       'crime', 'documentary', 'drama', 'family', 'fantasy', 'history',\n",
       "       'horror', 'music', 'mystery', 'romance', 'science_fiction', 'thriller',\n",
       "       'tv_movie', 'war', 'western', 'language_encoded',\n",
       "       'director_encoded_padded', 'writer_encoded_padded',\n",
       "       'cinematography_encoded_padded', 'composer_encoded_padded', 'cluster',\n",
       "       'lowercase_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[['name', 'key', 'action', 'adventure', 'animation', 'comedy',\n",
    "       'crime', 'documentary', 'drama', 'family', 'fantasy', 'history',\n",
    "       'horror', 'music', 'mystery', 'romance', 'science_fiction', 'thriller',\n",
    "       'tv_movie', 'war', 'western']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features_sparse_wolist(tfidf_matrix, X):\n",
    "    \"\"\"\n",
    "    Process and concatenate TF-IDF features with numerical/categorical features (sparse version).\n",
    "    \"\"\"\n",
    "    # ✅ Keep TF-IDF sparse\n",
    "    tfidf_sparse = csr_matrix(tfidf_matrix)  # No conversion to dense!\n",
    "\n",
    "    # ✅ Drop 'key' column before merging\n",
    "    X_numeric = X.drop(columns=['key', 'name'])\n",
    "\n",
    "    # ✅ Convert X_numeric to sparse matrix\n",
    "    X_numeric_sparse = csr_matrix(X_numeric.values)\n",
    "\n",
    "    # ✅ Concatenate using Scipy `hstack()` (efficient!)\n",
    "    X_final = hstack([tfidf_sparse, X_numeric_sparse])\n",
    "\n",
    "    return X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aybikealkan/.pyenv/versions/3.10.6/envs/movie_picker/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "X_final_new = preprocess_features_sparse_wolist(tfidf_matrix, X_new)\n",
    "kmeans, clusters = cluster_movies_kmeans_sparse(X_final_new)\n",
    "X[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Movie: Hell or High Water\n",
      "Similar Movie: Pig\n",
      "Similar Movie: Civil War\n",
      "Similar Movie: Total Recall\n",
      "Similar Movie: A Beautiful Mind\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_similar_movies_kmeans_knn_sparse(\"the Bourne supremacy\", X_final_new, X, kmeans, \"name\", n_neighbors=5)\n",
    "\n",
    "for movie in recommendations:\n",
    "    print(f\"Similar Movie: {movie}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn [35], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Embedding, Flatten, Concatenate, BatchNormalization, Dropout\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_autoencoder\u001b[39m(num_actors, num_directors, num_numeric, num_tfidf, num_genres, num_languages, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, encoding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Concatenate, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_autoencoder(num_actors, num_directors, num_numeric, num_tfidf, num_genres, num_languages, embedding_dim=50, encoding_dim=64):\n",
    "    \"\"\"\n",
    "    Build an autoencoder model incorporating embeddings for categorical features,\n",
    "    dense layers for numerical and high-dimensional TF-IDF features, and separate\n",
    "    inputs for one-hot encoded genres and languages.\n",
    "    \"\"\"\n",
    "    # Input layers\n",
    "    actor_input = Input(shape=(1,), name=\"actor_input\")\n",
    "    director_input = Input(shape=(1,), name=\"director_input\")\n",
    "    numeric_input = Input(shape=(num_numeric,), name=\"numeric_features\")\n",
    "    tfidf_input = Input(shape=(num_tfidf,), name=\"tfidf_features\")\n",
    "    genres_input = Input(shape=(num_genres,), name=\"genres_features\")\n",
    "    languages_input = Input(shape=(num_languages,), name=\"languages_features\")\n",
    "\n",
    "    # Embedding layers for categorical variables\n",
    "    actor_embedding = Embedding(input_dim=num_actors + 1, output_dim=embedding_dim, name=\"actor_embedding\")(actor_input)\n",
    "    director_embedding = Embedding(input_dim=num_directors + 1, output_dim=embedding_dim, name=\"director_embedding\")(director_input)\n",
    "\n",
    "    # Flatten embeddings\n",
    "    actor_embedding_flat = Flatten()(actor_embedding)\n",
    "    director_embedding_flat = Flatten()(director_embedding)\n",
    "\n",
    "    # Dense layer for TF-IDF features (dimensionality reduction)\n",
    "    tfidf_dense = Dense(128, activation='relu', name=\"tfidf_dense_layer\")(tfidf_input)\n",
    "\n",
    "    # Concatenate all features\n",
    "    concatenated = Concatenate()([\n",
    "        actor_embedding_flat,\n",
    "        director_embedding_flat,\n",
    "        numeric_input,\n",
    "        tfidf_dense,\n",
    "        genres_input,\n",
    "        languages_input\n",
    "    ])\n",
    "\n",
    "    # Encoder\n",
    "    encoded = Dense(256, activation='relu')(concatenated)\n",
    "    encoded = BatchNormalization()(encoded)\n",
    "    encoded = Dropout(0.3)(encoded)\n",
    "    encoded = Dense(128, activation='relu')(encoded)\n",
    "    bottleneck = Dense(encoding_dim, activation='relu', name=\"bottleneck_layer\")(encoded)  # Latent space\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Dense(128, activation='relu')(bottleneck)\n",
    "    decoded = BatchNormalization()(decoded)\n",
    "    decoded = Dropout(0.3)(decoded)\n",
    "    decoded = Dense(256, activation='relu')(decoded)\n",
    "    output_layer = Dense(num_numeric + num_tfidf + num_genres + num_languages, activation='sigmoid')(decoded)  # Reconstruct all inputs except categorical IDs\n",
    "\n",
    "    # Define models\n",
    "    autoencoder = Model(inputs=[actor_input, director_input, numeric_input, tfidf_input, genres_input, languages_input], outputs=output_layer)\n",
    "    encoder = Model(inputs=[actor_input, director_input, numeric_input, tfidf_input, genres_input, languages_input], outputs=bottleneck)\n",
    "\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return autoencoder, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<406445x335304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10796785 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
