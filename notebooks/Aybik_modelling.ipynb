{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>minute</th>\n",
       "      <th>rating</th>\n",
       "      <th>key</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>actor_list</th>\n",
       "      <th>language</th>\n",
       "      <th>studio_list</th>\n",
       "      <th>crew_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Barbie and Ken are having the time of their li...</td>\n",
       "      <td>114</td>\n",
       "      <td>3.86</td>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>comedy adventure</td>\n",
       "      <td>['Margot Robbie', 'Ryan Gosling', 'America Fer...</td>\n",
       "      <td>English</td>\n",
       "      <td>['LuckyChap Entertainment', 'Heyday Films', 'N...</td>\n",
       "      <td>{'Cinematography': ['Rodrigo Prieto'], 'Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>All unemployed, Ki-taek's family takes peculia...</td>\n",
       "      <td>133</td>\n",
       "      <td>4.56</td>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>comedy thriller drama</td>\n",
       "      <td>['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...</td>\n",
       "      <td>Korean</td>\n",
       "      <td>['Barunson E&amp;A']</td>\n",
       "      <td>{'Cinematography': ['Hong Kyung-pyo'], 'Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>An aging Chinese immigrant is swept up in an i...</td>\n",
       "      <td>140</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>science_fiction adventure comedy action</td>\n",
       "      <td>['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...</td>\n",
       "      <td>English</td>\n",
       "      <td>['IAC Films', 'AGBO', 'Ley Line Entertainment'...</td>\n",
       "      <td>{'Cinematography': ['Larkin Seiple'], 'Compose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>A ticking-time-bomb insomniac and a slippery s...</td>\n",
       "      <td>139</td>\n",
       "      <td>4.27</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>drama</td>\n",
       "      <td>['Edward Norton', 'Brad Pitt', 'Helena Bonham ...</td>\n",
       "      <td>English</td>\n",
       "      <td>['Fox 2000 Pictures', 'Regency Enterprises', '...</td>\n",
       "      <td>{'Cinematography': ['Jeff Cronenweth'], 'Compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Mia, an aspiring actress, serves lattes to mov...</td>\n",
       "      <td>129</td>\n",
       "      <td>4.09</td>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>drama comedy music romance</td>\n",
       "      <td>['Ryan Gosling', 'Emma Stone', 'John Legend', ...</td>\n",
       "      <td>English</td>\n",
       "      <td>['Summit Entertainment', 'Black Label Media', ...</td>\n",
       "      <td>{'Cinematography': ['Linus Sandgren'], 'Compos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               name    year  \\\n",
       "0  1000001                             Barbie  2023.0   \n",
       "1  1000002                           Parasite  2019.0   \n",
       "2  1000003  Everything Everywhere All at Once  2022.0   \n",
       "3  1000004                         Fight Club  1999.0   \n",
       "4  1000005                         La La Land  2016.0   \n",
       "\n",
       "                                         description  minute  rating  \\\n",
       "0  Barbie and Ken are having the time of their li...     114    3.86   \n",
       "1  All unemployed, Ki-taek's family takes peculia...     133    4.56   \n",
       "2  An aging Chinese immigrant is swept up in an i...     140    4.30   \n",
       "3  A ticking-time-bomb insomniac and a slippery s...     139    4.27   \n",
       "4  Mia, an aspiring actress, serves lattes to mov...     129    4.09   \n",
       "\n",
       "                                        key  \\\n",
       "0                             Barbie (2023)   \n",
       "1                           Parasite (2019)   \n",
       "2  Everything Everywhere All at Once (2022)   \n",
       "3                         Fight Club (1999)   \n",
       "4                         La La Land (2016)   \n",
       "\n",
       "                                genre_list  \\\n",
       "0                         comedy adventure   \n",
       "1                    comedy thriller drama   \n",
       "2  science_fiction adventure comedy action   \n",
       "3                                    drama   \n",
       "4               drama comedy music romance   \n",
       "\n",
       "                                          actor_list language  \\\n",
       "0  ['Margot Robbie', 'Ryan Gosling', 'America Fer...  English   \n",
       "1  ['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...   Korean   \n",
       "2  ['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...  English   \n",
       "3  ['Edward Norton', 'Brad Pitt', 'Helena Bonham ...  English   \n",
       "4  ['Ryan Gosling', 'Emma Stone', 'John Legend', ...  English   \n",
       "\n",
       "                                         studio_list  \\\n",
       "0  ['LuckyChap Entertainment', 'Heyday Films', 'N...   \n",
       "1                                   ['Barunson E&A']   \n",
       "2  ['IAC Films', 'AGBO', 'Ley Line Entertainment'...   \n",
       "3  ['Fox 2000 Pictures', 'Regency Enterprises', '...   \n",
       "4  ['Summit Entertainment', 'Black Label Media', ...   \n",
       "\n",
       "                                           crew_dict  \n",
       "0  {'Cinematography': ['Rodrigo Prieto'], 'Compos...  \n",
       "1  {'Cinematography': ['Hong Kyung-pyo'], 'Compos...  \n",
       "2  {'Cinematography': ['Larkin Seiple'], 'Compose...  \n",
       "3  {'Cinematography': ['Jeff Cronenweth'], 'Compo...  \n",
       "4  {'Cinematography': ['Linus Sandgren'], 'Compos...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir=os.path.dirname(current_dir)\n",
    "data= pd.read_csv(os.path.join(parent_dir, 'processed_data/final_data.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from keras_preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "def text_preprocess(sentence):\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers #TODO\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwords_removed = [w for w in tokenized_sentence if not w in stop_words]\n",
    "    v_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in stopwords_removed\n",
    "    ]\n",
    "    n_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\")\n",
    "        for word in v_lemmatized\n",
    "    ]\n",
    "    cleaned_sentence = ' '.join(word for word in n_lemmatized)\n",
    "    return cleaned_sentence\n",
    "\n",
    "def num_preprocess_year(value):\n",
    "    scaler = RobustScaler()\n",
    "    result = scaler.fit_transform(value)\n",
    "    return result\n",
    "\n",
    "def num_preprocess_min(value):\n",
    "    scaler = MinMaxScaler()\n",
    "    result = scaler.fit_transform(value)\n",
    "    return result\n",
    "\n",
    "def fix_data_from_csv(df):\n",
    "    df[[\"language\", \"genre_list\"]] = df[[\"language\", \"genre_list\"]].fillna(\"\")\n",
    "    return df\n",
    "\n",
    "######################### NEW INPUT #########################\n",
    "\n",
    "# changed this function ##\n",
    "def cat_processing_genre(df, column=\"genre_list\"):\n",
    "    # Initialize MultiLabelBinarizer and transform the data\n",
    "    encoder = MultiLabelBinarizer()\n",
    "    genre_df = pd.DataFrame(encoder.fit_transform(df[column].str.split(' ')),\n",
    "                                  columns=encoder.classes_,\n",
    "                                  index=df.index)\n",
    "    df = pd.concat([df, genre_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def cat_processing_lan(df, column=\"language\"):\n",
    "    \"\"\"\n",
    "    Cleans and encodes a single categorical column (e.g., language) using LabelEncoder.\n",
    "    - Keeps only the first value before delimiters (comma, slash, semicolon, pipe).\n",
    "    - Encodes categorical values into numerical labels.\n",
    "    \"\"\"\n",
    "\n",
    "    df[column] = df[column].astype(str).str.split(r\",|/|;|\\|\").str[0].str.strip()\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df[f\"{column}_encoded\"] = encoder.fit_transform(df[column])\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_eval_column(df, column_name=\"crew_dict\"):\n",
    "    \"\"\"\n",
    "    Safely converts a column containing string representations of dictionaries into actual dictionaries.\n",
    "    - If the value is already a dictionary, it remains unchanged.\n",
    "    - If the value is a valid string dictionary, it is converted using `ast.literal_eval`.\n",
    "    - If conversion fails, an empty dictionary `{}` is returned.\n",
    "    \"\"\"\n",
    "    def safe_eval(val):\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                return ast.literal_eval(val)  # Convert only if it's a valid string dictionary\n",
    "            except (ValueError, SyntaxError):\n",
    "                return {}  # Return empty dictionary if parsing fails\n",
    "        return val  # Return as is if already a dict\n",
    "\n",
    "    df[column_name] = df[column_name].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_roles(df, column_name=\"crew_dict\", roles=None):\n",
    "    \"\"\"\n",
    "    Extracts specific roles (e.g., Director, Writer) from a dictionary column.\n",
    "    Creates new columns for each role with lists of names.\n",
    "    \"\"\"\n",
    "    if roles is None:\n",
    "        roles = [\"Director\", \"Writer\", \"Cinematography\", \"Composer\"]\n",
    "\n",
    "    for role in roles:\n",
    "        df[role.lower()] = df[column_name].apply(\n",
    "            lambda x: x.get(role, []) if isinstance(x, dict) else []\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def encode_list_column_with_padding(df, column_name, padding_value=0, max_length=2):\n",
    "    \"\"\"\n",
    "    Encodes a column containing lists of categorical values (e.g., directors) and applies padding.\n",
    "    - Uses LabelEncoder to encode unique values.\n",
    "# - Pads sequences to a fixed length.\n",
    "# \"\"\"\n",
    "# # Flatten unique values for encoding\n",
    "# unique_values = sorted(set(value for sublist in df[column_name] for value in sublist))\n",
    "#\n",
    "# # Fit LabelEncoder once\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(unique_values)\n",
    "#\n",
    "# # Create mapping dictionary for faster lookup\n",
    "# encoding_map = {label: idx for idx, label in enumerate(encoder.classes_)}\n",
    "#\n",
    "# # Apply encoding efficiently\n",
    "# df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] for v in x])\n",
    "#\n",
    "# # Apply padding to ensure fixed-length sequences\n",
    "# df[f\"{column_name}_encoded_padded\"] = list(\n",
    "#     pad_sequences(df[f\"{column_name}_encoded\"], maxlen=max_length, padding='pre', value=padding_value)\n",
    "# )\n",
    "#\n",
    "# return df, len(unique_values)\n",
    "\n",
    "def data_preproc(df):\n",
    "    df = fix_data_from_csv(df)\n",
    "    df['description'] = df['description'].apply(text_preprocess)\n",
    "    df['year'] = num_preprocess_year(df[['year']])\n",
    "    df['minute'] = num_preprocess_min(df[['minute']])\n",
    "    df = cat_processing_genre(df,'genre_list') ## df equal added\n",
    "    df = cat_processing_lan(df, 'language')\n",
    "    return df\n",
    "\n",
    "def data_encode(df):\n",
    "    # Dictionary Processing\n",
    "    df = safe_eval_column(df, column_name=\"crew_dict\")\n",
    "    df = extract_roles(df, column_name=\"crew_dict\")\n",
    "\n",
    "    # Encoding list columns with padding\n",
    "    #df, director_length = encode_list_column_with_padding(df, \"director\")\n",
    "    #df, writer_length = encode_list_column_with_padding(df, \"writer\")\n",
    "    #df, cinematography_length = encode_list_column_with_padding(df, \"cinematography\")\n",
    "    #df, composer_length = encode_list_column_with_padding(df, \"composer\")\n",
    "#\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_preproc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'year', 'description', 'minute', 'rating', 'key',\n",
       "       'genre_list', 'actor_list', 'language', 'studio_list', 'crew_dict', '',\n",
       "       'action', 'adventure', 'animation', 'comedy', 'crime', 'documentary',\n",
       "       'drama', 'family', 'fantasy', 'history', 'horror', 'music', 'mystery',\n",
       "       'romance', 'science_fiction', 'thriller', 'tv_movie', 'war', 'western',\n",
       "       'language_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = data_encode(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>minute</th>\n",
       "      <th>rating</th>\n",
       "      <th>key</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>actor_list</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>science_fiction</th>\n",
       "      <th>thriller</th>\n",
       "      <th>tv_movie</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "      <th>language_encoded</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>cinematography</th>\n",
       "      <th>composer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>barbie ken time live colorful seemingly perfec...</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>3.86</td>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>comedy adventure</td>\n",
       "      <td>['Margot Robbie', 'Ryan Gosling', 'America Fer...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Greta Gerwig]</td>\n",
       "      <td>[Noah Baumbach, Greta Gerwig]</td>\n",
       "      <td>[Rodrigo Prieto]</td>\n",
       "      <td>[Mark Ronson, Andrew Wyatt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>unemployed kitaeks family take peculiar intere...</td>\n",
       "      <td>0.462312</td>\n",
       "      <td>4.56</td>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>comedy thriller drama</td>\n",
       "      <td>['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...</td>\n",
       "      <td>Korean</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>[Bong Joon-ho]</td>\n",
       "      <td>[Kim Dae-hwan, Bong Joon-ho, Han Jin-won]</td>\n",
       "      <td>[Hong Kyung-pyo]</td>\n",
       "      <td>[Jung Jae-il]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>age chinese immigrant sweep insane adventure a...</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>science_fiction adventure comedy action</td>\n",
       "      <td>['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Daniel Scheinert, Daniel Kwan]</td>\n",
       "      <td>[Daniel Kwan, Daniel Scheinert]</td>\n",
       "      <td>[Larkin Seiple]</td>\n",
       "      <td>[Ryan Lott, Rafiq Bhatia, Ian Chang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>-0.25000</td>\n",
       "      <td>tickingtimebomb insomniac slippery soap salesm...</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>4.27</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>drama</td>\n",
       "      <td>['Edward Norton', 'Brad Pitt', 'Helena Bonham ...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[David Fincher]</td>\n",
       "      <td>[Jim Uhls, Andrew Kevin Walker]</td>\n",
       "      <td>[Jeff Cronenweth]</td>\n",
       "      <td>[John King, Michael Simpson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>mia aspire actress serve latte movie star audi...</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>4.09</td>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>drama comedy music romance</td>\n",
       "      <td>['Ryan Gosling', 'Emma Stone', 'John Legend', ...</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[Damien Chazelle]</td>\n",
       "      <td>[Damien Chazelle]</td>\n",
       "      <td>[Linus Sandgren]</td>\n",
       "      <td>[Justin Hurwitz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406440</th>\n",
       "      <td>1941583</td>\n",
       "      <td>日本統一56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one day special investigation team suddenly be...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一56</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406441</th>\n",
       "      <td>1941584</td>\n",
       "      <td>日本統一57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hamadas death seem yuseikais problem would res...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一57</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406442</th>\n",
       "      <td>1941585</td>\n",
       "      <td>日本統一58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>makimoto tomohiro waki arimura tasuku nagaoka ...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一58</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406443</th>\n",
       "      <td>1941586</td>\n",
       "      <td>日本統一59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one day himuro yasufu motomiya tamura yoshiyuk...</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一59</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406444</th>\n",
       "      <td>1941587</td>\n",
       "      <td>日本統一60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>himuro yasufu motomiya start fight crush shimi...</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>日本統一60</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406445 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                               name     year  \\\n",
       "0       1000001                             Barbie  0.50000   \n",
       "1       1000002                           Parasite  0.37500   \n",
       "2       1000003  Everything Everywhere All at Once  0.46875   \n",
       "3       1000004                         Fight Club -0.25000   \n",
       "4       1000005                         La La Land  0.28125   \n",
       "...         ...                                ...      ...   \n",
       "406440  1941583                             日本統一56      NaN   \n",
       "406441  1941584                             日本統一57      NaN   \n",
       "406442  1941585                             日本統一58      NaN   \n",
       "406443  1941586                             日本統一59      NaN   \n",
       "406444  1941587                             日本統一60      NaN   \n",
       "\n",
       "                                              description    minute  rating  \\\n",
       "0       barbie ken time live colorful seemingly perfec...  0.366834    3.86   \n",
       "1       unemployed kitaeks family take peculiar intere...  0.462312    4.56   \n",
       "2       age chinese immigrant sweep insane adventure a...  0.497487    4.30   \n",
       "3       tickingtimebomb insomniac slippery soap salesm...  0.492462    4.27   \n",
       "4       mia aspire actress serve latte movie star audi...  0.442211    4.09   \n",
       "...                                                   ...       ...     ...   \n",
       "406440  one day special investigation team suddenly be...  0.145729     NaN   \n",
       "406441  hamadas death seem yuseikais problem would res...  0.145729     NaN   \n",
       "406442  makimoto tomohiro waki arimura tasuku nagaoka ...  0.145729     NaN   \n",
       "406443  one day himuro yasufu motomiya tamura yoshiyuk...  0.150754     NaN   \n",
       "406444  himuro yasufu motomiya start fight crush shimi...  0.145729     NaN   \n",
       "\n",
       "                                             key  \\\n",
       "0                                  Barbie (2023)   \n",
       "1                                Parasite (2019)   \n",
       "2       Everything Everywhere All at Once (2022)   \n",
       "3                              Fight Club (1999)   \n",
       "4                              La La Land (2016)   \n",
       "...                                          ...   \n",
       "406440                                    日本統一56   \n",
       "406441                                    日本統一57   \n",
       "406442                                    日本統一58   \n",
       "406443                                    日本統一59   \n",
       "406444                                    日本統一60   \n",
       "\n",
       "                                     genre_list  \\\n",
       "0                              comedy adventure   \n",
       "1                         comedy thriller drama   \n",
       "2       science_fiction adventure comedy action   \n",
       "3                                         drama   \n",
       "4                    drama comedy music romance   \n",
       "...                                         ...   \n",
       "406440                                            \n",
       "406441                                            \n",
       "406442                                            \n",
       "406443                                            \n",
       "406444                                            \n",
       "\n",
       "                                               actor_list language  ...  \\\n",
       "0       ['Margot Robbie', 'Ryan Gosling', 'America Fer...  English  ...   \n",
       "1       ['Song Kang-ho', 'Lee Sun-kyun', 'Cho Yeo-jeon...   Korean  ...   \n",
       "2       ['Michelle Yeoh', 'Ke Huy Quan', 'Stephanie Hs...  English  ...   \n",
       "3       ['Edward Norton', 'Brad Pitt', 'Helena Bonham ...  English  ...   \n",
       "4       ['Ryan Gosling', 'Emma Stone', 'John Legend', ...  English  ...   \n",
       "...                                                   ...      ...  ...   \n",
       "406440                                                 []  English  ...   \n",
       "406441                                                 []  English  ...   \n",
       "406442                                                 []  English  ...   \n",
       "406443                                                 []  English  ...   \n",
       "406444                                                 []  English  ...   \n",
       "\n",
       "       science_fiction thriller  tv_movie  war  western  language_encoded  \\\n",
       "0                    0        0         0    0        0                38   \n",
       "1                    0        1         0    0        0                77   \n",
       "2                    1        0         0    0        0                38   \n",
       "3                    0        0         0    0        0                38   \n",
       "4                    0        0         0    0        0                38   \n",
       "...                ...      ...       ...  ...      ...               ...   \n",
       "406440               0        0         0    0        0                38   \n",
       "406441               0        0         0    0        0                38   \n",
       "406442               0        0         0    0        0                38   \n",
       "406443               0        0         0    0        0                38   \n",
       "406444               0        0         0    0        0                38   \n",
       "\n",
       "                               director  \\\n",
       "0                        [Greta Gerwig]   \n",
       "1                        [Bong Joon-ho]   \n",
       "2       [Daniel Scheinert, Daniel Kwan]   \n",
       "3                       [David Fincher]   \n",
       "4                     [Damien Chazelle]   \n",
       "...                                 ...   \n",
       "406440                               []   \n",
       "406441                               []   \n",
       "406442                               []   \n",
       "406443                               []   \n",
       "406444                               []   \n",
       "\n",
       "                                           writer     cinematography  \\\n",
       "0                   [Noah Baumbach, Greta Gerwig]   [Rodrigo Prieto]   \n",
       "1       [Kim Dae-hwan, Bong Joon-ho, Han Jin-won]   [Hong Kyung-pyo]   \n",
       "2                 [Daniel Kwan, Daniel Scheinert]    [Larkin Seiple]   \n",
       "3                 [Jim Uhls, Andrew Kevin Walker]  [Jeff Cronenweth]   \n",
       "4                               [Damien Chazelle]   [Linus Sandgren]   \n",
       "...                                           ...                ...   \n",
       "406440                                         []                 []   \n",
       "406441                                         []                 []   \n",
       "406442                                         []                 []   \n",
       "406443                                         []                 []   \n",
       "406444                                         []                 []   \n",
       "\n",
       "                                    composer  \n",
       "0                [Mark Ronson, Andrew Wyatt]  \n",
       "1                              [Jung Jae-il]  \n",
       "2       [Ryan Lott, Rafiq Bhatia, Ian Chang]  \n",
       "3               [John King, Michael Simpson]  \n",
       "4                           [Justin Hurwitz]  \n",
       "...                                      ...  \n",
       "406440                                    []  \n",
       "406441                                    []  \n",
       "406442                                    []  \n",
       "406443                                    []  \n",
       "406444                                    []  \n",
       "\n",
       "[406445 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(data_encoded[0])\n",
    "df = data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "name                     0\n",
       "year                 15719\n",
       "description              0\n",
       "minute                   0\n",
       "rating              331222\n",
       "key                      0\n",
       "genre_list               0\n",
       "actor_list               0\n",
       "language                 0\n",
       "studio_list              0\n",
       "crew_dict            38988\n",
       "                         0\n",
       "action                   0\n",
       "adventure                0\n",
       "animation                0\n",
       "comedy                   0\n",
       "crime                    0\n",
       "documentary              0\n",
       "drama                    0\n",
       "family                   0\n",
       "fantasy                  0\n",
       "history                  0\n",
       "horror                   0\n",
       "music                    0\n",
       "mystery                  0\n",
       "romance                  0\n",
       "science_fiction          0\n",
       "thriller                 0\n",
       "tv_movie                 0\n",
       "war                      0\n",
       "western                  0\n",
       "language_encoded         0\n",
       "director                 0\n",
       "writer                   0\n",
       "cinematography           0\n",
       "composer                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFIDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "tfidf_dim=2500\n",
    "\n",
    "def vectorize_descriptions(df, text_column):\n",
    "    \"\"\"\n",
    "    Vectorize movie descriptions using TF-IDF.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing movie descriptions.\n",
    "        text_column: The column in the DataFrame that contains descriptions.\n",
    "\n",
    "    Returns:\n",
    "        tfidf_matrix: The TF-IDF matrix.\n",
    "        vectorizer: The fitted TfidfVectorizer object (useful if needed later).\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=tfidf_dim)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[text_column])\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    return tfidf_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbie (2023)</td>\n",
       "      <td>barbie ken time live colorful seemingly perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parasite (2019)</td>\n",
       "      <td>unemployed kitaeks family take peculiar intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>age chinese immigrant sweep insane adventure a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>tickingtimebomb insomniac slippery soap salesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La La Land (2016)</td>\n",
       "      <td>mia aspire actress serve latte movie star audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406440</th>\n",
       "      <td>日本統一56</td>\n",
       "      <td>one day special investigation team suddenly be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406441</th>\n",
       "      <td>日本統一57</td>\n",
       "      <td>hamadas death seem yuseikais problem would res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406442</th>\n",
       "      <td>日本統一58</td>\n",
       "      <td>makimoto tomohiro waki arimura tasuku nagaoka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406443</th>\n",
       "      <td>日本統一59</td>\n",
       "      <td>one day himuro yasufu motomiya tamura yoshiyuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406444</th>\n",
       "      <td>日本統一60</td>\n",
       "      <td>himuro yasufu motomiya start fight crush shimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406445 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             key  \\\n",
       "0                                  Barbie (2023)   \n",
       "1                                Parasite (2019)   \n",
       "2       Everything Everywhere All at Once (2022)   \n",
       "3                              Fight Club (1999)   \n",
       "4                              La La Land (2016)   \n",
       "...                                          ...   \n",
       "406440                                    日本統一56   \n",
       "406441                                    日本統一57   \n",
       "406442                                    日本統一58   \n",
       "406443                                    日本統一59   \n",
       "406444                                    日本統一60   \n",
       "\n",
       "                                              description  \n",
       "0       barbie ken time live colorful seemingly perfec...  \n",
       "1       unemployed kitaeks family take peculiar intere...  \n",
       "2       age chinese immigrant sweep insane adventure a...  \n",
       "3       tickingtimebomb insomniac slippery soap salesm...  \n",
       "4       mia aspire actress serve latte movie star audi...  \n",
       "...                                                   ...  \n",
       "406440  one day special investigation team suddenly be...  \n",
       "406441  hamadas death seem yuseikais problem would res...  \n",
       "406442  makimoto tomohiro waki arimura tasuku nagaoka ...  \n",
       "406443  one day himuro yasufu motomiya tamura yoshiyuk...  \n",
       "406444  himuro yasufu motomiya start fight crush shimi...  \n",
       "\n",
       "[406445 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = df[['key', 'description']]\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = vectorize_descriptions(text_df, 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_languages = df.language_encoded.nunique()\n",
    "num_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38]\n",
      " [77]\n",
      " [38]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]]\n"
     ]
    }
   ],
   "source": [
    "language_data = df.language_encoded\n",
    "language_data_np = np.array(language_data, dtype=np.int32).reshape(-1, 1)\n",
    "print(language_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genres= 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "genre_columns = ['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary',\n",
    "                 'drama', 'family', 'fantasy', 'history', 'horror', 'music', 'mystery',\n",
    "                 'romance', 'science_fiction', 'thriller', 'tv_movie', 'war', 'western']\n",
    "genres_data_np = df[genre_columns].values\n",
    "print(genres_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_encoder(tfidf_dim, num_languages, num_genres):\n",
    "    \"\"\"\n",
    "    Builds an encoder model that fuses:\n",
    "      - A TF-IDF vector input (continuous, shape: [tfidf_dim])\n",
    "      - A language input (integer, shape: [1])\n",
    "      - A one-hot encoded genres input (shape: [num_genres])\n",
    "\n",
    "    Parameters:\n",
    "      tfidf_dim (int): Dimensionality of the TF-IDF vector (e.g., 2500).\n",
    "      num_languages (int): Total number of language categories (max language index + 1).\n",
    "      num_genres (int): Number of genres (should be 19 for your columns).\n",
    "\n",
    "    Returns:\n",
    "      encoder_model (tf.keras.Model): A model that outputs a fused latent embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # TF-IDF Branch\n",
    "    # -------------------------\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    tfidf_dense = tf.keras.layers.Dense(128, activation='relu', name=\"tfidf_dense\")(tfidf_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Language Branch\n",
    "    # -------------------------\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    language_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_languages,\n",
    "        output_dim=8,\n",
    "        name=\"language_embedding\"\n",
    "    )(language_input)\n",
    "    language_vector = tf.keras.layers.Flatten(name=\"language_flatten\")(language_embedding)\n",
    "\n",
    "    # -------------------------\n",
    "    # Genres Branch (One-hot encoded)\n",
    "    # -------------------------\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "    # Optionally, pass the one-hot vector through a dense layer to learn a compressed representation.\n",
    "    genre_dense = tf.keras.layers.Dense(32, activation='relu', name=\"genre_dense\")(genre_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Merge Branches\n",
    "    # -------------------------\n",
    "    # Concatenate the outputs of all branches.\n",
    "    merged = tf.keras.layers.concatenate([tfidf_dense, language_vector, genre_dense], name=\"merged_features\")\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name=\"dense_1\")(merged)\n",
    "    final_embedding = tf.keras.layers.Dense(32, activation='relu', name=\"final_embedding\")(x)\n",
    "\n",
    "    # Build the encoder model\n",
    "    encoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input],\n",
    "        outputs=final_embedding\n",
    "    )\n",
    "\n",
    "    return encoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_autoencoder(tfidf_dim, num_languages, num_genres):\n",
    "    \"\"\"\n",
    "    Builds an autoencoder that uses:\n",
    "      - The encoder from build_encoder to produce a 32-d latent embedding.\n",
    "      - Three decoder branches to reconstruct:\n",
    "          A. The original TF-IDF vector.\n",
    "          B. The language (as a probability distribution over num_languages).\n",
    "          C. The one-hot encoded genres vector.\n",
    "\n",
    "    The autoencoder is compiled with MSE loss for TF-IDF, sparse categorical crossentropy for language,\n",
    "    and binary crossentropy for genres.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the inputs (they will be passed to both encoder and as targets later)\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "\n",
    "    # Build the encoder and get the latent representation.\n",
    "    encoder = build_encoder(tfidf_dim, num_languages, num_genres)\n",
    "    latent = encoder([tfidf_input, language_input, genre_input])\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for TF-IDF reconstruction\n",
    "    # -------------------------\n",
    "    decoder_tfidf = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_tfidf_dense\")(latent)\n",
    "    tfidf_output = tf.keras.layers.Dense(tfidf_dim, activation='relu', name=\"tfidf_output\")(decoder_tfidf)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Language reconstruction\n",
    "    # -------------------------\n",
    "    decoder_language = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_language_dense\")(latent)\n",
    "    # Output is a probability distribution over languages\n",
    "    language_output = tf.keras.layers.Dense(num_languages, activation='softmax', name=\"language_output\")(decoder_language)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Genres reconstruction\n",
    "    # -------------------------\n",
    "    decoder_genre = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_genre_dense\")(latent)\n",
    "    # For multi-label, we use sigmoid activation; if it's strictly one-hot, you could use softmax.\n",
    "    genre_output = tf.keras.layers.Dense(num_genres, activation='sigmoid', name=\"genre_output\")(decoder_genre)\n",
    "\n",
    "    # Build the autoencoder model.\n",
    "    autoencoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input],\n",
    "        outputs=[tfidf_output, language_output, genre_output],\n",
    "        name=\"autoencoder\"\n",
    "    )\n",
    "\n",
    "    # Compile the autoencoder:\n",
    "    # - For TF-IDF, we use mean squared error.\n",
    "    # - For language, we use sparse categorical crossentropy (the target should be an integer).\n",
    "    # - For genres, binary crossentropy is appropriate for multi-label reconstruction.\n",
    "    autoencoder_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'tfidf_output': 'mse',\n",
    "            'language_output': 'sparse_categorical_crossentropy',\n",
    "            'genre_output': 'binary_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'tfidf_output': 1.0,\n",
    "            'language_output': 1.0,\n",
    "            'genre_output': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return autoencoder_model, encoder\n",
    "\n",
    "# Example usage:\n",
    "tfidf_dim = 2500      # Dimensionality of your TF-IDF vectors\n",
    "num_languages = 172   # For example, if your full dataset has 172 unique languages (0..171)\n",
    "num_genres = 19       # One column per genre: action, adventure, ..., western\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " tfidf_input (InputLayer)       [(None, 2500)]       0           []                               \n",
      "                                                                                                  \n",
      " language_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " genre_input (InputLayer)       [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 32)           335040      ['tfidf_input[0][0]',            \n",
      "                                                                  'language_input[0][0]',         \n",
      "                                                                  'genre_input[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_tfidf_dense (Dense)    (None, 64)           2112        ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " decoder_language_dense (Dense)  (None, 16)          528         ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " decoder_genre_dense (Dense)    (None, 16)           528         ['model_1[0][0]']                \n",
      "                                                                                                  \n",
      " tfidf_output (Dense)           (None, 2500)         162500      ['decoder_tfidf_dense[0][0]']    \n",
      "                                                                                                  \n",
      " language_output (Dense)        (None, 172)          2924        ['decoder_language_dense[0][0]'] \n",
      "                                                                                                  \n",
      " genre_output (Dense)           (None, 19)           323         ['decoder_genre_dense[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 503,955\n",
      "Trainable params: 503,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model, encoder_model = build_autoencoder(tfidf_dim, num_languages, num_genres)\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 21:00:11.556632: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25403/25403 [==============================] - 75s 3ms/step - loss: 0.1616 - tfidf_output_loss: 3.9912e-04 - language_output_loss: 0.1318 - genre_output_loss: 0.0294\n",
      "Epoch 2/10\n",
      "25403/25403 [==============================] - 70s 3ms/step - loss: 0.0254 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0187 - genre_output_loss: 0.0062\n",
      "Epoch 3/10\n",
      "25403/25403 [==============================] - 66s 3ms/step - loss: 0.0161 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0114 - genre_output_loss: 0.0043\n",
      "Epoch 4/10\n",
      "25403/25403 [==============================] - 62s 2ms/step - loss: 0.0133 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0095 - genre_output_loss: 0.0034\n",
      "Epoch 5/10\n",
      "25403/25403 [==============================] - 65s 3ms/step - loss: 0.0108 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0076 - genre_output_loss: 0.0027\n",
      "Epoch 6/10\n",
      "25403/25403 [==============================] - 61s 2ms/step - loss: 0.0097 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0069 - genre_output_loss: 0.0024\n",
      "Epoch 7/10\n",
      "25403/25403 [==============================] - 58s 2ms/step - loss: 0.0094 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0069 - genre_output_loss: 0.0021\n",
      "Epoch 8/10\n",
      "25403/25403 [==============================] - 54s 2ms/step - loss: 0.0087 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0063 - genre_output_loss: 0.0020\n",
      "Epoch 9/10\n",
      "25403/25403 [==============================] - 56s 2ms/step - loss: 0.0083 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0061 - genre_output_loss: 0.0019\n",
      "Epoch 10/10\n",
      "25403/25403 [==============================] - 58s 2ms/step - loss: 0.0079 - tfidf_output_loss: 3.9911e-04 - language_output_loss: 0.0057 - genre_output_loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x54a7c30d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor the validation loss\n",
    "    patience=3,               # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "history = autoencoder_model.fit(\n",
    "    x=[tfidf_array, language_data_np, genres_data_np],\n",
    "    y=[tfidf_array, language_data_np, genres_data_np],\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12702/12702 [==============================] - 15s 1ms/step\n",
      "Latent embeddings shape: (406445, 32)\n"
     ]
    }
   ],
   "source": [
    "# xtract latent embeddings using the encoder model.\n",
    "latent_embeddings = encoder_model.predict([tfidf_array, language_data_np, genres_data_np])\n",
    "print(\"Latent embeddings shape:\", latent_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = os.path.join(parent_dir, \"processed_data\", \"latent_embeddings.pkl\")\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(latent_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a KNN model for similarity search using the latent embeddings.\n",
    "n_neighbors = 5\n",
    "knn_model = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine')\n",
    "knn_model.fit(latent_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found movie 'The bourne identity'.\n",
      "Recommended Movies:\n",
      "- Conspiracy Theory (Distance: 0.000006)\n",
      "- The Stranger (Distance: 0.000006)\n",
      "- Oldboy (Distance: 0.000006)\n",
      "- The Bourne Ultimatum (Distance: 0.000006)\n",
      "- Flashpoint (Distance: 0.000006)\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The bourne identity\"  # Example input\n",
    "\n",
    "# Convert both the user input and the DataFrame names to lowercase for case-insensitive matching.\n",
    "matched_rows = df[df[\"name\"].str.lower() == user_input.lower()]\n",
    "\n",
    "if matched_rows.empty:\n",
    "    print(\"Movie not found.\")\n",
    "else:\n",
    "    # Get the first matching index (handle multiple matches as needed)\n",
    "    sample_index = matched_rows.index[0]\n",
    "    print(f\"Found movie '{user_input}'.\")\n",
    "\n",
    "    # Retrieve KNN results.\n",
    "    distances, indices = knn_model.kneighbors(latent_embeddings[sample_index].reshape(1, -1))\n",
    "\n",
    "    # Convert to 1D arrays.\n",
    "    indices = indices.flatten()\n",
    "    distances = distances.flatten()\n",
    "\n",
    "    # Filter out the queried movie (its index should match sample_index).\n",
    "    filtered_recs = [(idx, dist) for idx, dist in zip(indices, distances) if idx != sample_index]\n",
    "\n",
    "    # If the filtered recommendations list is empty or too short, you may want to handle that.\n",
    "    if not filtered_recs:\n",
    "        print(\"No recommendations found after filtering out the queried movie.\")\n",
    "    else:\n",
    "        print(\"Recommended Movies:\")\n",
    "        for idx, dist in filtered_recs:\n",
    "            movie_name = df.loc[idx, \"name\"]\n",
    "            print(f\"- {movie_name} (Distance: {dist:.6f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_list_column_first(df, column_name, reserve_zero=True, default_value=0):\n",
    "    \"\"\"\n",
    "    Encodes a column containing lists of categorical values (e.g., directors) and\n",
    "    extracts only the first encoded value from each list.\n",
    "\n",
    "    - Uses LabelEncoder to encode unique values.\n",
    "    - Optionally offsets encoding so that 0 is reserved for a default value\n",
    "      (i.e., valid values start at 1).\n",
    "    - Instead of padding, extracts only the first director from each list.\n",
    "\n",
    "    Parameters:\n",
    "      df: pandas DataFrame.\n",
    "      column_name: Name of the column containing lists to be encoded.\n",
    "      reserve_zero: If True, adds 1 to each encoded value so that 0 is reserved for default.\n",
    "      default_value: The value to use if the list is empty (default is 0).\n",
    "\n",
    "    Returns:\n",
    "      The modified DataFrame with a new column <column_name>_encoded_first.\n",
    "    \"\"\"\n",
    "    # Flatten unique values for encoding\n",
    "    unique_values = sorted(set(value for sublist in df[column_name] for value in sublist))\n",
    "\n",
    "    # Fit LabelEncoder on the unique values\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(unique_values)\n",
    "\n",
    "    # Create a mapping dictionary for faster lookup\n",
    "    encoding_map = {label: idx for idx, label in enumerate(encoder.classes_)}\n",
    "\n",
    "    if reserve_zero:\n",
    "        # Offset each encoded value by 1 so that 0 is reserved for default.\n",
    "        df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] + 1 for v in x])\n",
    "    else:\n",
    "        df[f\"{column_name}_encoded\"] = df[column_name].apply(lambda x: [encoding_map[v] for v in x])\n",
    "\n",
    "    # Instead of padding, take only the first element if available; otherwise, use default_value.\n",
    "    df[f\"{column_name}_encoded_first\"] = df[f\"{column_name}_encoded\"].apply(\n",
    "        lambda x: x[0] if len(x) > 0 else default_value\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_unique(df, column_name):\n",
    "    # Assuming your encoded values are stored in <column_name>_encoded\n",
    "    # and you offset them (if reserve_zero was True).\n",
    "    unique_vals = set(val for sublist in df[f\"{column_name}_encoded\"] for val in sublist)\n",
    "    return len(unique_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_list_column_first(df, \"director\", reserve_zero=True, default_value=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_directors = calculate_num_unique(df, \"director\")\n",
    "print(\"Number of unique directors:\", num_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_data = df.director_encoded_first\n",
    "director_data_np = np.array(director_data, dtype=np.int32).reshape(-1, 1)\n",
    "print(director_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode: Directors, Tfidf, language, genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_encoder2(tfidf_dim, num_languages, num_genres, num_directors):\n",
    "    \"\"\"\n",
    "    Builds an encoder model that fuses:\n",
    "      - A TF-IDF vector input (continuous, shape: [tfidf_dim])\n",
    "      - A language input (integer, shape: [1])\n",
    "      - A one-hot encoded genres input (shape: [num_genres])\n",
    "      - A director input (integer, shape: [1])\n",
    "\n",
    "    Parameters:\n",
    "      tfidf_dim (int): Dimensionality of the TF-IDF vector (e.g., 2500).\n",
    "      num_languages (int): Total number of language categories (max language index + 1).\n",
    "      num_genres (int): Number of genres (should be 19 for your columns).\n",
    "      num_directors (int): Total number of unique director tokens (max director index + 1).\n",
    "\n",
    "    Returns:\n",
    "      encoder_model (tf.keras.Model): A model that outputs a fused latent embedding.\n",
    "    \"\"\"\n",
    "    # -------------------------\n",
    "    # TF-IDF Branch\n",
    "    # -------------------------\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    tfidf_dense = tf.keras.layers.Dense(128, activation='relu', name=\"tfidf_dense\")(tfidf_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Language Branch\n",
    "    # -------------------------\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    language_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_languages,\n",
    "        output_dim=8,\n",
    "        name=\"language_embedding\"\n",
    "    )(language_input)\n",
    "    language_vector = tf.keras.layers.Flatten(name=\"language_flatten\")(language_embedding)\n",
    "\n",
    "    # -------------------------\n",
    "    # Genres Branch (One-hot encoded)\n",
    "    # -------------------------\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "    # Optionally, pass the one-hot vector through a dense layer.\n",
    "    genre_dense = tf.keras.layers.Dense(32, activation='relu', name=\"genre_dense\")(genre_input)\n",
    "\n",
    "    # -------------------------\n",
    "    # Director Branch\n",
    "    # -------------------------\n",
    "    director_input = tf.keras.layers.Input(shape=(1,), name=\"director_input\")\n",
    "    director_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_directors,\n",
    "        output_dim=16,\n",
    "        name=\"director_embedding\"\n",
    "    )(director_input)\n",
    "    director_vector = tf.keras.layers.Flatten(name=\"director_flatten\")(director_embedding)\n",
    "\n",
    "    # -------------------------\n",
    "    # Merge All Branches\n",
    "    # -------------------------\n",
    "    merged = tf.keras.layers.concatenate(\n",
    "        [tfidf_dense, language_vector, genre_dense, director_vector],\n",
    "        name=\"merged_features\"\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name=\"dense_1\")(merged)\n",
    "    final_embedding = tf.keras.layers.Dense(32, activation='relu', name=\"final_embedding\")(x)\n",
    "\n",
    "    # Build the encoder model with 4 inputs.\n",
    "    encoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input, director_input],\n",
    "        outputs=final_embedding,\n",
    "        name=\"encoder\"\n",
    "    )\n",
    "\n",
    "    return encoder_model\n",
    "\n",
    "\n",
    "def build_autoencoder2(tfidf_dim, num_languages, num_genres, num_directors):\n",
    "    \"\"\"\n",
    "    Builds an autoencoder that uses:\n",
    "      - The encoder from build_encoder to produce a 32-d latent embedding.\n",
    "      - Four decoder branches to reconstruct:\n",
    "          A. The original TF-IDF vector.\n",
    "          B. The language (as a probability distribution over num_languages).\n",
    "          C. The one-hot encoded genres vector.\n",
    "          D. The director (as a probability distribution over num_directors).\n",
    "\n",
    "    The autoencoder is compiled with:\n",
    "      - MSE loss for TF-IDF.\n",
    "      - Sparse categorical crossentropy for language and director.\n",
    "      - Binary crossentropy for genres.\n",
    "    \"\"\"\n",
    "    # Define inputs (to be used as both inputs and targets).\n",
    "    tfidf_input = tf.keras.layers.Input(shape=(tfidf_dim,), name=\"tfidf_input\")\n",
    "    language_input = tf.keras.layers.Input(shape=(1,), name=\"language_input\")\n",
    "    genre_input = tf.keras.layers.Input(shape=(num_genres,), name=\"genre_input\")\n",
    "    director_input = tf.keras.layers.Input(shape=(1,), name=\"director_input\")\n",
    "\n",
    "    # Build the encoder and get the latent representation.\n",
    "    encoder = build_encoder2(tfidf_dim, num_languages, num_genres, num_directors)\n",
    "    latent = encoder([tfidf_input, language_input, genre_input, director_input])\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for TF-IDF reconstruction\n",
    "    # -------------------------\n",
    "    decoder_tfidf = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_tfidf_dense\")(latent)\n",
    "    tfidf_output = tf.keras.layers.Dense(tfidf_dim, activation='relu', name=\"tfidf_output\")(decoder_tfidf)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Language reconstruction\n",
    "    # -------------------------\n",
    "    decoder_language = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_language_dense\")(latent)\n",
    "    language_output = tf.keras.layers.Dense(num_languages, activation='softmax', name=\"language_output\")(decoder_language)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Genres reconstruction\n",
    "    # -------------------------\n",
    "    decoder_genre = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_genre_dense\")(latent)\n",
    "    genre_output = tf.keras.layers.Dense(num_genres, activation='sigmoid', name=\"genre_output\")(decoder_genre)\n",
    "\n",
    "    # -------------------------\n",
    "    # Decoder for Director reconstruction\n",
    "    # -------------------------\n",
    "    decoder_director = tf.keras.layers.Dense(16, activation='relu', name=\"decoder_director_dense\")(latent)\n",
    "    director_output = tf.keras.layers.Dense(num_directors, activation='softmax', name=\"director_output\")(decoder_director)\n",
    "\n",
    "    # Build the autoencoder model with four inputs and four outputs.\n",
    "    autoencoder_model = tf.keras.models.Model(\n",
    "        inputs=[tfidf_input, language_input, genre_input, director_input],\n",
    "        outputs=[tfidf_output, language_output, genre_output, director_output],\n",
    "        name=\"autoencoder\"\n",
    "    )\n",
    "\n",
    "    # Compile the model.\n",
    "    autoencoder_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'tfidf_output': 'mse',\n",
    "            'language_output': 'sparse_categorical_crossentropy',\n",
    "            'genre_output': 'binary_crossentropy',\n",
    "            'director_output': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'tfidf_output': 1.0,\n",
    "            'language_output': 1.0,\n",
    "            'genre_output': 1.0,\n",
    "            'director_output': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return autoencoder_model, encoder\n",
    "\n",
    "# Example usage:\n",
    "tfidf_dim = 2500      # Dimensionality of your TF-IDF vectors\n",
    "num_languages = 172   # e.g., if your full dataset has 172 unique languages (indices 0..171)\n",
    "num_genres = 19       # One column per genre: action, adventure, ..., western\n",
    "num_directors = num_directors\n",
    "\n",
    "autoencoder_model2, encoder_model2 = build_autoencoder2(tfidf_dim, num_languages, num_genres, num_directors)\n",
    "autoencoder_model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor the validation loss\n",
    "    patience=3,               # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "history2 = autoencoder_model2.fit(\n",
    "    x=[tfidf_array, language_data_np, genres_data_np, director_data_np],  # Inputs\n",
    "    y=[tfidf_array, language_data_np, genres_data_np, director_data_np],  # Targets\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means and Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚀 Full Workflow for K-Means + KNN Movie Recommendation\n",
    "This approach:\n",
    "\n",
    "Prepares data (TF-IDF + numerical/categorical features) ✅\n",
    "Clusters movies using K-Means ✅\n",
    "Applies KNN only within the closest cluster ✅\n",
    "Returns top-K similar movies efficiently ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use sparse instead of df**\n",
    "✅ Keeps TF-IDF sparse (NO toarray() conversion) → Saves RAM\n",
    "✅ Uses hstack() for memory-efficient feature merging\n",
    "✅ Clusters movies using MiniBatchKMeans to reduce computation\n",
    "✅ Limits KNN search to relevant clusters → 10x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def expand_list_columns(df, list_columns, max_elements=2):\n",
    "    \"\"\"\n",
    "    Expand list-type columns into separate numerical columns.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame\n",
    "        list_columns: List of column names that contain lists\n",
    "        max_elements: Number of elements to extract from each list (default=2)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with expanded columns.\n",
    "    \"\"\"\n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [0] * max_elements)  # Handle NaNs\n",
    "        for i in range(max_elements):\n",
    "            df[f'{col}_{i}'] = df[col].apply(lambda x: x[i] if len(x) > i else 0)  # Extract element i\n",
    "        df.drop(columns=[col], inplace=True)  # Drop original column\n",
    "    return df\n",
    "\n",
    "def preprocess_features_sparse(tfidf_matrix, X):\n",
    "    \"\"\"\n",
    "    Process and concatenate TF-IDF features with numerical/categorical features (sparse version).\n",
    "    \"\"\"\n",
    "    # ✅ Keep TF-IDF sparse\n",
    "    tfidf_sparse = csr_matrix(tfidf_matrix)  # No conversion to dense!\n",
    "\n",
    "    # ✅ Drop 'key' column before merging\n",
    "    X_numeric = X.drop(columns=['key', 'name'])\n",
    "\n",
    "    # ✅ Convert list-type columns into separate numerical columns\n",
    "    list_columns = [\n",
    "        'director_encoded_padded', 'writer_encoded_padded',\n",
    "        'cinematography_encoded_padded', 'composer_encoded_padded'\n",
    "    ]\n",
    "    X_numeric = expand_list_columns(X_numeric, list_columns)\n",
    "\n",
    "    # ✅ Convert X_numeric to sparse matrix\n",
    "    X_numeric_sparse = csr_matrix(X_numeric.values)\n",
    "\n",
    "    # ✅ Concatenate using Scipy `hstack()` (efficient!)\n",
    "    X_final = hstack([tfidf_sparse, X_numeric_sparse])\n",
    "\n",
    "    return X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def cluster_movies_kmeans_sparse(X_final, n_clusters=200):\n",
    "    \"\"\"\n",
    "    Cluster movies using K-Means on sparse matrix.\n",
    "    \"\"\"\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=1024)\n",
    "    clusters = kmeans.fit_predict(X_final)\n",
    "\n",
    "    return kmeans, clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies_kmeans_knn_sparse(movie_name, X_final, df, kmeans, name_column, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Find similar movies using KNN within the assigned cluster from K-Means (Sparse Matrix version).\n",
    "    Handles case-insensitive movie name search.\n",
    "    \"\"\"\n",
    "    # ✅ Convert movie names in DataFrame to lowercase for case-insensitive search\n",
    "    df['lowercase_name'] = df[name_column].str.lower()\n",
    "\n",
    "    # ✅ Convert input movie name to lowercase\n",
    "    movie_name_lower = movie_name.lower()\n",
    "\n",
    "    # ✅ Verify movie exists (case-insensitive search)\n",
    "    if movie_name_lower not in df['lowercase_name'].values:\n",
    "        raise ValueError(f\"Movie '{movie_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # ✅ Get index of input movie\n",
    "    idx = df[df['lowercase_name'] == movie_name_lower].index[0]\n",
    "\n",
    "    # ✅ Predict the cluster for the input movie\n",
    "    movie_cluster = kmeans.predict(X_final[idx].reshape(1, -1))[0]\n",
    "\n",
    "    # ✅ Get indices of movies in the same cluster\n",
    "    cluster_indices = df[df[\"cluster\"] == movie_cluster].index\n",
    "\n",
    "    # ✅ Apply KNN only within the cluster\n",
    "    knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn_model.fit(X_final[cluster_indices])\n",
    "\n",
    "    # ✅ Find K-nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors(X_final[idx].reshape(1, -1), n_neighbors=n_neighbors + 1)\n",
    "\n",
    "    return df.iloc[indices.flatten()[1:]][name_column].tolist()  # Exclude input movie itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = preprocess_features_sparse(tfidf_matrix, X)  # This should NOT crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aybikealkan/.pyenv/versions/3.10.6/envs/movie_picker/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "kmeans, clusters = cluster_movies_kmeans_sparse(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Movie: The Wolf of Wall Street\n",
      "Similar Movie: Requiem for a Dream\n",
      "Similar Movie: Easy A\n",
      "Similar Movie: Bring It On\n",
      "Similar Movie: Zoolander\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_similar_movies_kmeans_knn_sparse(\"the bourne ultimatum\", X_final, X, kmeans, \"name\", n_neighbors=5)\n",
    "\n",
    "for movie in recommendations:\n",
    "    print(f\"Similar Movie: {movie}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'minute', 'key', 'action', 'adventure', 'animation', 'comedy',\n",
       "       'crime', 'documentary', 'drama', 'family', 'fantasy', 'history',\n",
       "       'horror', 'music', 'mystery', 'romance', 'science_fiction', 'thriller',\n",
       "       'tv_movie', 'war', 'western', 'language_encoded',\n",
       "       'director_encoded_padded', 'writer_encoded_padded',\n",
       "       'cinematography_encoded_padded', 'composer_encoded_padded', 'cluster',\n",
       "       'lowercase_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[['name', 'key', 'action', 'adventure', 'animation', 'comedy',\n",
    "       'crime', 'documentary', 'drama', 'family', 'fantasy', 'history',\n",
    "       'horror', 'music', 'mystery', 'romance', 'science_fiction', 'thriller',\n",
    "       'tv_movie', 'war', 'western']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features_sparse_wolist(tfidf_matrix, X):\n",
    "    \"\"\"\n",
    "    Process and concatenate TF-IDF features with numerical/categorical features (sparse version).\n",
    "    \"\"\"\n",
    "    # ✅ Keep TF-IDF sparse\n",
    "    tfidf_sparse = csr_matrix(tfidf_matrix)  # No conversion to dense!\n",
    "\n",
    "    # ✅ Drop 'key' column before merging\n",
    "    X_numeric = X.drop(columns=['key', 'name'])\n",
    "\n",
    "    # ✅ Convert X_numeric to sparse matrix\n",
    "    X_numeric_sparse = csr_matrix(X_numeric.values)\n",
    "\n",
    "    # ✅ Concatenate using Scipy `hstack()` (efficient!)\n",
    "    X_final = hstack([tfidf_sparse, X_numeric_sparse])\n",
    "\n",
    "    return X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aybikealkan/.pyenv/versions/3.10.6/envs/movie_picker/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "X_final_new = preprocess_features_sparse_wolist(tfidf_matrix, X_new)\n",
    "kmeans, clusters = cluster_movies_kmeans_sparse(X_final_new)\n",
    "X[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Movie: Hell or High Water\n",
      "Similar Movie: Pig\n",
      "Similar Movie: Civil War\n",
      "Similar Movie: Total Recall\n",
      "Similar Movie: A Beautiful Mind\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_similar_movies_kmeans_knn_sparse(\"the Bourne supremacy\", X_final_new, X, kmeans, \"name\", n_neighbors=5)\n",
    "\n",
    "for movie in recommendations:\n",
    "    print(f\"Similar Movie: {movie}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn [35], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Embedding, Flatten, Concatenate, BatchNormalization, Dropout\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_autoencoder\u001b[39m(num_actors, num_directors, num_numeric, num_tfidf, num_genres, num_languages, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, encoding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Concatenate, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_autoencoder(num_actors, num_directors, num_numeric, num_tfidf, num_genres, num_languages, embedding_dim=50, encoding_dim=64):\n",
    "    \"\"\"\n",
    "    Build an autoencoder model incorporating embeddings for categorical features,\n",
    "    dense layers for numerical and high-dimensional TF-IDF features, and separate\n",
    "    inputs for one-hot encoded genres and languages.\n",
    "    \"\"\"\n",
    "    # Input layers\n",
    "    actor_input = Input(shape=(1,), name=\"actor_input\")\n",
    "    director_input = Input(shape=(1,), name=\"director_input\")\n",
    "    numeric_input = Input(shape=(num_numeric,), name=\"numeric_features\")\n",
    "    tfidf_input = Input(shape=(num_tfidf,), name=\"tfidf_features\")\n",
    "    genres_input = Input(shape=(num_genres,), name=\"genres_features\")\n",
    "    languages_input = Input(shape=(num_languages,), name=\"languages_features\")\n",
    "\n",
    "    # Embedding layers for categorical variables\n",
    "    actor_embedding = Embedding(input_dim=num_actors + 1, output_dim=embedding_dim, name=\"actor_embedding\")(actor_input)\n",
    "    director_embedding = Embedding(input_dim=num_directors + 1, output_dim=embedding_dim, name=\"director_embedding\")(director_input)\n",
    "\n",
    "    # Flatten embeddings\n",
    "    actor_embedding_flat = Flatten()(actor_embedding)\n",
    "    director_embedding_flat = Flatten()(director_embedding)\n",
    "\n",
    "    # Dense layer for TF-IDF features (dimensionality reduction)\n",
    "    tfidf_dense = Dense(128, activation='relu', name=\"tfidf_dense_layer\")(tfidf_input)\n",
    "\n",
    "    # Concatenate all features\n",
    "    concatenated = Concatenate()([\n",
    "        actor_embedding_flat,\n",
    "        director_embedding_flat,\n",
    "        numeric_input,\n",
    "        tfidf_dense,\n",
    "        genres_input,\n",
    "        languages_input\n",
    "    ])\n",
    "\n",
    "    # Encoder\n",
    "    encoded = Dense(256, activation='relu')(concatenated)\n",
    "    encoded = BatchNormalization()(encoded)\n",
    "    encoded = Dropout(0.3)(encoded)\n",
    "    encoded = Dense(128, activation='relu')(encoded)\n",
    "    bottleneck = Dense(encoding_dim, activation='relu', name=\"bottleneck_layer\")(encoded)  # Latent space\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Dense(128, activation='relu')(bottleneck)\n",
    "    decoded = BatchNormalization()(decoded)\n",
    "    decoded = Dropout(0.3)(decoded)\n",
    "    decoded = Dense(256, activation='relu')(decoded)\n",
    "    output_layer = Dense(num_numeric + num_tfidf + num_genres + num_languages, activation='sigmoid')(decoded)  # Reconstruct all inputs except categorical IDs\n",
    "\n",
    "    # Define models\n",
    "    autoencoder = Model(inputs=[actor_input, director_input, numeric_input, tfidf_input, genres_input, languages_input], outputs=output_layer)\n",
    "    encoder = Model(inputs=[actor_input, director_input, numeric_input, tfidf_input, genres_input, languages_input], outputs=bottleneck)\n",
    "\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return autoencoder, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<406445x335304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10796785 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
